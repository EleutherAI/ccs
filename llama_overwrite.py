overwrite_30b = {
    "model.embed_tokens": 0,
    "model.layers.0": 0,
    "model.layers.1": 0,
    "model.layers.2": 0,
    "model.layers.3": 0,
    "model.layers.4": 0,
    "model.layers.5": 0,
    "model.layers.6": 0,
    "model.layers.7": 0,
    "model.layers.8": 0,
    "model.layers.9": 0,
    "model.layers.10": 0,
    "model.layers.11": 0,
    "model.layers.12": 0,
    "model.layers.13": 0,
    "model.layers.14": 0,
    "model.layers.15": 0,
    "model.layers.16": 0,
    "model.layers.17": 0,
    "model.layers.18": 0,
    "model.layers.19": 0,
    "model.layers.20": 0,
    "model.layers.21": 0,
    "model.layers.22": 0,
    "model.layers.23": 0,
    "model.layers.24": 0,
    "model.layers.25": 0,
    "model.layers.26": 0,
    "model.layers.27": 0,
    "model.layers.28": 0,
    "model.layers.29": 0,
    "model.layers.30": 0,
    "model.layers.31": 0,
    "model.layers.32": 0,
    "model.layers.33": 0,
    "model.layers.34": 0,
    "model.layers.35": 0,
    "model.layers.36": 0,
    "model.layers.37": 0,
    "model.layers.38": 0,
    "model.layers.39": 0,
    "model.layers.40": 0,
    "model.layers.41": 0,
    "model.layers.42.self_attn.q_proj": 1,
    "model.layers.42.self_attn.k_proj": 1,
    "model.layers.42.self_attn.v_proj": 1,
    "model.layers.42.self_attn.o_proj": 1,
    "model.layers.42.self_attn.rotary_emb": 1,
    "model.layers.42.mlp": 1,
    "model.layers.42.input_layernorm": 1,
    "model.layers.42.post_attention_layernorm": 1,
    "model.layers.43": 1,
    "model.layers.44": 1,
    "model.layers.45": 1,
    "model.layers.46": 1,
    "model.layers.47": 1,
    "model.layers.48": 1,
    "model.layers.49": 1,
    "model.layers.50": 1,
    "model.layers.51": 1,
    "model.layers.52": 1,
    "model.layers.53": 1,
    "model.layers.54": 1,
    "model.layers.55": 1,
    "model.layers.56": 1,
    "model.layers.57": 1,
    "model.layers.58": 1,
    "model.layers.59": 1,
    "model.norm": 1,
    "lm_head": 1,
}
