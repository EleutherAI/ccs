{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "\n",
    "options_file = \"elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\"\n",
    "weights_file = \"elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\"\n",
    "model = Elmo(options_file, weights_file, 1, dropout=0).eval()\n",
    "tokenizer = MosesTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[259,  74, 116, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 117, 105, 106, 116, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  98, 111, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  70,  77,  78, 112, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 115, 102, 113, 115, 102, 116, 102, 111, 117,  98, 117, 106, 112,\n",
       "          111, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  64, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  90, 102, 116, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261]],\n",
       "\n",
       "        [[259,  74, 116, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 117, 105, 106, 116, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  98, 111, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  70,  77,  78, 112, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 115, 102, 113, 115, 102, 116, 102, 111, 117,  98, 117, 106, 112,\n",
       "          111, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  64, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  79, 112, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [\"Is this an ELMo representation? Yes\", \"Is this an ELMo representation? No\"]\n",
    "tokens = [tokenizer.tokenize(sequence, escape=False) for sequence in sequences]\n",
    "character_ids = batch_to_ids(tokens)\n",
    "character_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8412, -0.1165,  0.5267,  ...,  0.4512, -0.1392,  0.2720],\n",
       "         [-0.6446, -0.0498,  0.3769,  ...,  0.4740, -0.1965,  0.0583],\n",
       "         [-0.2392,  1.1553,  0.1504,  ..., -0.0441, -0.4352,  0.2593],\n",
       "         ...,\n",
       "         [-0.3401, -0.1522,  0.0504,  ...,  0.1691, -0.0028, -0.2495],\n",
       "         [-0.1372,  0.0519,  0.0663,  ...,  1.1651,  0.6015, -0.1530],\n",
       "         [-0.2489, -0.0674,  0.5087,  ...,  0.5525, -0.2275,  0.5592]],\n",
       "\n",
       "        [[-0.8412, -0.1165,  0.5267,  ...,  0.5106, -0.0239,  0.3420],\n",
       "         [-0.6446, -0.0498,  0.3769,  ...,  0.5673, -0.0058,  0.2063],\n",
       "         [-0.2392,  1.1553,  0.1504,  ..., -0.0058, -0.2897,  0.3701],\n",
       "         ...,\n",
       "         [-0.3401, -0.1522,  0.0504,  ...,  0.1757, -0.0016,  0.1202],\n",
       "         [-0.1372,  0.0519,  0.0663,  ...,  1.1888,  0.6638, -0.0508],\n",
       "         [ 0.0425,  0.0044,  0.2477,  ...,  0.1274, -0.0031,  0.7462]]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model(character_ids)\n",
    "representations = embeddings[\"elmo_representations\"][0]\n",
    "representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8412, -0.1165,  0.5267,  ...,  0.4512, -0.1392,  0.2720],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([-0.8412, -0.1165,  0.5267,  ...,  0.5106, -0.0239,  0.3420],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "yes_rep = representations[0]\n",
    "print(yes_rep[0])\n",
    "no_rep = representations[1]\n",
    "print(no_rep[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class ElmoModel(PreTrainedModel):\n",
    "    def __init__(self, options_file, weights_file):\n",
    "        super().__init__(config=PretrainedConfig())\n",
    "        self.elmo_model = Elmo(options_file, weights_file, 1, dropout=0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, labels=None):\n",
    "        return self.elmo_model(input_ids)[\"elmo_representations\"][0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_pretrained(path):\n",
    "        return ElmoModel(options_file, weights_file)\n",
    "\n",
    "class ElmoTokenizer(PreTrainedTokenizer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.tokenizer = MosesTokenizer()\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        batch = text if isinstance(text, (list, tuple)) else [text]\n",
    "        tokens = [self.tokenizer.tokenize(sequence, escape=False) for sequence in sequences]\n",
    "        character_ids = batch_to_ids(tokens)\n",
    "        return character_ids\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_pretrained(path):\n",
    "        return ElmoTokenizer()\n",
    "\n",
    "\n",
    "tokenizer = ElmoTokenizer.from_pretrained(\"elmo\")\n",
    "inputs = [\"Is this an ELMo representation? Yes\", \"Is this an ELMo representation? No\"]\n",
    "character_ids = tokenizer(inputs)\n",
    "model = ElmoModel.from_pretrained(\"elmo\")\n",
    "embeddings = model(character_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 1024])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyle-rnn-experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
