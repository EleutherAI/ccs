{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/kyle/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from sacremoses import MosesTokenizer\n",
    "from transformers import (\n",
    "    PretrainedConfig,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    ")\n",
    "\n",
    "class ElmoConfig(PretrainedConfig):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_size = 1024\n",
    "        self.num_hidden_layers = 1\n",
    "        self.is_encoder_decoder = False\n",
    "\n",
    "class ElmoModel(PreTrainedModel):\n",
    "    def __init__(self, options_file, weights_file):\n",
    "        super().__init__(config=ElmoConfig())\n",
    "        self.elmo_model = Elmo(options_file, weights_file, 1, dropout=0)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        return self.elmo_model(input_ids)[\"elmo_representations\"][0]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_pretrained(path):\n",
    "        options_file = (\n",
    "            \"/home/kyle/elk/elk/rnn/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\"\n",
    "        )\n",
    "        weights_file = (\n",
    "            \"/home/kyle/elk/elk/rnn/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\"\n",
    "        )\n",
    "        return ElmoModel(options_file, weights_file)\n",
    "\n",
    "class ElmoTokenizer(PreTrainedTokenizer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.tokenizer = MosesTokenizer()\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "\n",
    "    def __call__(self, text, return_tensors, truncation):\n",
    "        sequences = text if isinstance(text, list) else [text]\n",
    "        tokens = [\n",
    "            [self.wnl.lemmatize(token) for token in self.tokenizer.tokenize(sequence, escape=False)] for sequence in sequences\n",
    "        ]\n",
    "        character_ids = batch_to_ids(text)  # type: ignore\n",
    "        return character_ids\n",
    "\n",
    "    @staticmethod\n",
    "    def from_pretrained(path):\n",
    "        return ElmoTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 37, 50])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [\"Is this an ELMo representation? Yes\", \"Is this an ELMo representation? No\", \"Is this an ELMo representation? Maybe\"]\n",
    "elmo_tokenizer = ElmoTokenizer()\n",
    "tokenized_sequences = elmo_tokenizer(sequences, return_tensors=\"pt\", truncation=True)\n",
    "tokenized_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8412, -0.1165,  0.5267,  ...,  0.4512, -0.1392,  0.2720],\n",
       "        [-0.6446, -0.0498,  0.3769,  ...,  0.4740, -0.1965,  0.0583],\n",
       "        [-0.2392,  1.1553,  0.1504,  ..., -0.0441, -0.4352,  0.2593],\n",
       "        ...,\n",
       "        [-0.3401, -0.1522,  0.0504,  ...,  0.1691, -0.0028, -0.2495],\n",
       "        [-0.1372,  0.0519,  0.0663,  ...,  1.1651,  0.6015, -0.1530],\n",
       "        [-0.2489, -0.0674,  0.5087,  ...,  0.5525, -0.2275,  0.5592]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "elmo_model = ElmoModel.from_pretrained(\"elmo\")\n",
    "embeddings = elmo_model(tokenized_sequences)\n",
    "print(embeddings.shape)\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0004, -0.0064,  0.0055, -0.0080, -0.0164, -0.0010,  0.0106],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1372,  0.0519,  0.0663,  ...,  1.1888,  0.6638, -0.0508],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[1][-2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 9, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mask': tensor([[True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True]]),\n",
       " 'token_embedding': tensor([[[-8.5709e+00, -9.9289e+00,  4.0575e+00,  ...,  9.1735e+00,\n",
       "            8.3215e+00, -6.9233e+00],\n",
       "          [-1.3800e-02, -2.2660e-01, -3.4851e-02,  ...,  1.9179e-01,\n",
       "            4.6514e-02, -2.2795e-02],\n",
       "          [-6.0722e-02,  5.1529e-02,  1.8452e-02,  ...,  2.3105e-01,\n",
       "            3.6155e-03,  4.1534e-02],\n",
       "          ...,\n",
       "          [ 6.4416e-01, -7.7645e-02,  7.0715e-02,  ...,  6.5416e-01,\n",
       "            5.1353e-01, -2.2917e-02],\n",
       "          [-3.8933e-01,  8.6538e-01,  1.1729e-01,  ...,  4.5468e-01,\n",
       "           -9.4481e-02,  2.5647e-01],\n",
       "          [-1.2410e-01, -3.2147e+00, -6.1114e+00,  ...,  9.8041e+00,\n",
       "            1.9380e+00, -8.1160e+00]],\n",
       " \n",
       "         [[-8.5709e+00, -9.9289e+00,  4.0575e+00,  ...,  9.1735e+00,\n",
       "            8.3215e+00, -6.9233e+00],\n",
       "          [-1.3800e-02, -2.2660e-01, -3.4851e-02,  ...,  1.9179e-01,\n",
       "            4.6514e-02, -2.2795e-02],\n",
       "          [-6.0722e-02,  5.1529e-02,  1.8452e-02,  ...,  2.3105e-01,\n",
       "            3.6155e-03,  4.1534e-02],\n",
       "          ...,\n",
       "          [ 6.4416e-01, -7.7645e-02,  7.0715e-02,  ...,  6.5416e-01,\n",
       "            5.1353e-01, -2.2917e-02],\n",
       "          [-2.5356e-01,  6.0378e-01, -1.8716e-01,  ...,  9.0713e-02,\n",
       "           -3.6864e-01,  4.2334e-01],\n",
       "          [-1.2410e-01, -3.2147e+00, -6.1114e+00,  ...,  9.8041e+00,\n",
       "            1.9380e+00, -8.1160e+00]],\n",
       " \n",
       "         [[-8.5709e+00, -9.9289e+00,  4.0575e+00,  ...,  9.1735e+00,\n",
       "            8.3215e+00, -6.9233e+00],\n",
       "          [-1.3800e-02, -2.2660e-01, -3.4851e-02,  ...,  1.9179e-01,\n",
       "            4.6514e-02, -2.2795e-02],\n",
       "          [-6.0722e-02,  5.1529e-02,  1.8452e-02,  ...,  2.3105e-01,\n",
       "            3.6155e-03,  4.1534e-02],\n",
       "          ...,\n",
       "          [ 6.4416e-01, -7.7645e-02,  7.0715e-02,  ...,  6.5416e-01,\n",
       "            5.1353e-01, -2.2917e-02],\n",
       "          [-1.3765e-01, -3.0527e-01, -5.1513e-01,  ...,  7.0863e-01,\n",
       "            3.2935e-01, -3.8413e-01],\n",
       "          [-1.2410e-01, -3.2147e+00, -6.1114e+00,  ...,  9.8041e+00,\n",
       "            1.9380e+00, -8.1160e+00]]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilm_lstm = elmo_model.elmo_model._elmo_lstm\n",
    "lstm_token_embedder = bilm_lstm._token_embedder\n",
    "internal_embeddings = lstm_token_embedder(tokenized_sequences)\n",
    "print(internal_embeddings[\"token_embedding\"].shape)\n",
    "internal_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 9, 1024])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = bilm_lstm(tokenized_sequences)[\"activations\"]\n",
    "activations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 9, 1024])\n",
      "512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.2756e-02,  2.9971e-02,  2.5870e-02,  ...,  1.2941e-01,\n",
       "            1.2591e-01,  2.0738e-02],\n",
       "          [-6.6910e-01, -6.9574e-03,  5.6632e-01,  ...,  3.4151e-01,\n",
       "           -3.7841e-01,  2.6081e-01],\n",
       "          [-8.1336e-01, -2.1257e-03,  1.5202e-01,  ...,  3.8662e-01,\n",
       "           -6.2787e-01,  1.0230e-02],\n",
       "          ...,\n",
       "          [-4.7419e-01,  2.3019e-01, -5.5697e-02,  ...,  1.1738e-01,\n",
       "           -2.6359e-01,  9.8556e-03],\n",
       "          [ 9.7131e-02, -3.3274e-02,  7.3773e-01,  ...,  2.8967e-01,\n",
       "            1.6298e-01,  3.8194e-01],\n",
       "          [ 2.4646e-01,  6.4309e-01,  1.6108e-01,  ...,  1.9356e-01,\n",
       "           -6.8029e-03,  1.8191e-03]],\n",
       "\n",
       "         [[ 2.2720e-02,  3.0274e-02,  2.5760e-02,  ...,  1.3126e-01,\n",
       "            1.2724e-01,  2.0480e-02],\n",
       "          [-6.6751e-01, -6.3711e-03,  5.6428e-01,  ...,  3.5123e-01,\n",
       "           -3.4959e-01,  2.6068e-01],\n",
       "          [-8.1317e-01, -2.1860e-03,  1.5058e-01,  ...,  4.0542e-01,\n",
       "           -5.8162e-01, -4.1161e-03],\n",
       "          ...,\n",
       "          [-4.7367e-01,  2.3072e-01, -5.5787e-02,  ...,  1.1869e-01,\n",
       "           -1.7217e-01, -1.0341e-01],\n",
       "          [ 1.7677e-01, -6.9893e-02,  5.4465e-01,  ...,  1.3286e-01,\n",
       "            2.6775e-01,  4.4987e-01],\n",
       "          [ 2.6889e-01,  5.6559e-01,  1.4429e-01,  ...,  1.9361e-01,\n",
       "           -6.7716e-03,  1.7177e-03]],\n",
       "\n",
       "         [[ 2.2729e-02,  3.0202e-02,  2.5786e-02,  ...,  1.2409e-01,\n",
       "            1.2121e-01,  2.0273e-02],\n",
       "          [-6.6789e-01, -6.3574e-03,  5.6465e-01,  ...,  3.0767e-01,\n",
       "           -4.1337e-01,  2.4141e-01],\n",
       "          [-8.1278e-01, -2.5071e-03,  1.5086e-01,  ...,  3.4636e-01,\n",
       "           -6.4413e-01, -1.9628e-02],\n",
       "          ...,\n",
       "          [-4.7371e-01,  2.3061e-01, -5.5687e-02,  ...,  6.3688e-03,\n",
       "           -4.5894e-01, -1.8618e-01],\n",
       "          [-9.4402e-02, -6.8530e-02, -1.5639e-01,  ..., -4.1388e-02,\n",
       "            1.0405e-02,  1.8480e-02],\n",
       "          [ 2.6650e-01,  6.0509e-01,  1.8163e-01,  ...,  1.9397e-01,\n",
       "           -6.4380e-03,  1.0341e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 6.6564e-02,  1.1043e-01,  1.6825e-02,  ...,  4.3486e-01,\n",
       "            5.7120e-01, -5.0854e-01],\n",
       "          [-9.3045e-01,  9.6891e-02,  5.9570e-01,  ...,  5.3742e-01,\n",
       "           -8.1681e-01,  3.9966e-01],\n",
       "          [-5.7822e-01, -1.6094e-01,  6.4307e-01,  ...,  1.2806e+00,\n",
       "           -6.1705e-01,  2.7984e-01],\n",
       "          ...,\n",
       "          [-5.1083e-01,  1.3582e-01,  6.5807e-02,  ...,  2.7937e-01,\n",
       "           -3.1061e-01,  4.4900e-01],\n",
       "          [-2.8337e-01, -7.4715e-01,  5.5427e-01,  ...,  6.0131e-01,\n",
       "           -9.1542e-02,  8.7991e-01],\n",
       "          [ 2.9210e-01,  4.8987e-01,  2.6921e-01,  ...,  3.4323e-01,\n",
       "            1.7425e-01, -2.8956e-01]],\n",
       "\n",
       "         [[ 7.0253e-02,  1.0670e-01,  1.8604e-02,  ...,  3.7374e-01,\n",
       "            6.3872e-01, -5.3076e-01],\n",
       "          [-9.3248e-01,  9.5281e-02,  5.9354e-01,  ...,  6.2057e-01,\n",
       "           -6.7904e-01,  3.5022e-01],\n",
       "          [-5.7994e-01, -1.6302e-01,  6.4185e-01,  ...,  1.3307e+00,\n",
       "           -5.3933e-01,  2.2364e-01],\n",
       "          ...,\n",
       "          [-5.1114e-01,  1.3686e-01,  6.5954e-02,  ...,  6.0898e-01,\n",
       "           -1.0096e-01, -6.6615e-02],\n",
       "          [ 4.3515e-01, -3.5767e-01,  2.3713e-01,  ...,  6.6506e-01,\n",
       "            3.3154e-01,  7.7222e-01],\n",
       "          [ 2.5256e-01,  4.2861e-01,  3.2695e-01,  ...,  3.4869e-01,\n",
       "            1.7597e-01, -2.9027e-01]],\n",
       "\n",
       "         [[ 7.0844e-02,  1.1197e-01,  1.7217e-02,  ...,  4.4166e-01,\n",
       "            5.7776e-01, -5.5802e-01],\n",
       "          [-9.3054e-01,  9.5859e-02,  5.9385e-01,  ...,  5.5698e-01,\n",
       "           -8.2081e-01,  3.8847e-01],\n",
       "          [-5.7858e-01, -1.6461e-01,  6.4081e-01,  ...,  1.1636e+00,\n",
       "           -4.3913e-01,  2.8523e-01],\n",
       "          ...,\n",
       "          [-5.0719e-01,  1.3666e-01,  6.2376e-02,  ..., -3.1502e-02,\n",
       "           -1.4516e-01,  2.1635e-01],\n",
       "          [-3.0891e-01, -2.2202e-01,  1.0800e-01,  ..., -1.0879e-02,\n",
       "            7.7173e-01,  2.5286e-01],\n",
       "          [ 1.0797e-01,  4.7326e-01,  2.8101e-01,  ...,  3.4189e-01,\n",
       "            1.7266e-01, -2.9314e-01]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internal_bilm = bilm_lstm._elmo_lstm\n",
    "bilm_hidden_states = internal_bilm(inputs=internal_embeddings[\"token_embedding\"], mask=internal_embeddings[\"mask\"])\n",
    "print(bilm_hidden_states.shape)\n",
    "print(internal_bilm.hidden_size)\n",
    "\n",
    "# Calling the internal BiLM directly gives the hidden states for each layer. There are two layers.\n",
    "# The output tensor is of shape (2, batch_size, sequence_length, 1012 (512 * 2?))\n",
    "bilm_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0228, 0.0300, 0.0259,  ..., 0.1294, 0.1259, 0.0207])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilm_hidden_states[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 9, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[[-8.5709e+00, -9.9289e+00,  4.0575e+00,  ...,  9.1735e+00,\n",
       "            8.3215e+00, -6.9233e+00],\n",
       "          [-1.3800e-02, -2.2660e-01, -3.4851e-02,  ...,  1.9179e-01,\n",
       "            4.6514e-02, -2.2795e-02],\n",
       "          [-6.0722e-02,  5.1529e-02,  1.8452e-02,  ...,  2.3105e-01,\n",
       "            3.6155e-03,  4.1534e-02],\n",
       "          ...,\n",
       "          [ 6.4416e-01, -7.7645e-02,  7.0715e-02,  ...,  6.5416e-01,\n",
       "            5.1353e-01, -2.2917e-02],\n",
       "          [-3.8933e-01,  8.6538e-01,  1.1729e-01,  ...,  4.5468e-01,\n",
       "           -9.4481e-02,  2.5647e-01],\n",
       "          [-1.2410e-01, -3.2147e+00, -6.1114e+00,  ...,  9.8041e+00,\n",
       "            1.9380e+00, -8.1160e+00]],\n",
       " \n",
       "         [[-8.5709e+00, -9.9289e+00,  4.0575e+00,  ...,  9.1735e+00,\n",
       "            8.3215e+00, -6.9233e+00],\n",
       "          [-1.3800e-02, -2.2660e-01, -3.4851e-02,  ...,  1.9179e-01,\n",
       "            4.6514e-02, -2.2795e-02],\n",
       "          [-6.0722e-02,  5.1529e-02,  1.8452e-02,  ...,  2.3105e-01,\n",
       "            3.6155e-03,  4.1534e-02],\n",
       "          ...,\n",
       "          [ 6.4416e-01, -7.7645e-02,  7.0715e-02,  ...,  6.5416e-01,\n",
       "            5.1353e-01, -2.2917e-02],\n",
       "          [-2.5356e-01,  6.0378e-01, -1.8716e-01,  ...,  9.0713e-02,\n",
       "           -3.6864e-01,  4.2334e-01],\n",
       "          [-1.2410e-01, -3.2147e+00, -6.1114e+00,  ...,  9.8041e+00,\n",
       "            1.9380e+00, -8.1160e+00]],\n",
       " \n",
       "         [[-8.5709e+00, -9.9289e+00,  4.0575e+00,  ...,  9.1735e+00,\n",
       "            8.3215e+00, -6.9233e+00],\n",
       "          [-1.3800e-02, -2.2660e-01, -3.4851e-02,  ...,  1.9179e-01,\n",
       "            4.6514e-02, -2.2795e-02],\n",
       "          [-6.0722e-02,  5.1529e-02,  1.8452e-02,  ...,  2.3105e-01,\n",
       "            3.6155e-03,  4.1534e-02],\n",
       "          ...,\n",
       "          [ 6.4416e-01, -7.7645e-02,  7.0715e-02,  ...,  6.5416e-01,\n",
       "            5.1353e-01, -2.2917e-02],\n",
       "          [-1.3765e-01, -3.0527e-01, -5.1513e-01,  ...,  7.0863e-01,\n",
       "            3.2935e-01, -3.8413e-01],\n",
       "          [-1.2410e-01, -3.2147e+00, -6.1114e+00,  ...,  9.8041e+00,\n",
       "            1.9380e+00, -8.1160e+00]]]),\n",
       " tensor([[[ 2.1402e-02,  4.1391e-02,  2.1766e-02,  ...,  1.2840e-01,\n",
       "            1.2478e-01,  2.2046e-02],\n",
       "          [-6.1109e-01,  3.0436e-02,  5.0740e-01,  ...,  3.5066e-01,\n",
       "           -3.8449e-01,  2.6277e-01],\n",
       "          [-7.9793e-01,  1.4074e-02,  1.1477e-01,  ...,  3.9032e-01,\n",
       "           -6.3174e-01,  1.3628e-02],\n",
       "          ...,\n",
       "          [-4.5005e-01,  2.5129e-01, -6.3272e-02,  ...,  1.1605e-01,\n",
       "           -2.6077e-01,  1.5613e-02],\n",
       "          [ 9.0611e-02, -9.3908e-03,  7.1414e-01,  ...,  2.9706e-01,\n",
       "            1.6546e-01,  3.9847e-01],\n",
       "          [ 2.4638e-01,  6.5596e-01,  1.4954e-01,  ...,  1.9226e-01,\n",
       "           -7.8551e-03,  4.3966e-03]],\n",
       " \n",
       "         [[ 2.1351e-02,  4.1821e-02,  2.1611e-02,  ...,  1.3061e-01,\n",
       "            1.2659e-01,  2.1659e-02],\n",
       "          [-6.0911e-01,  3.1343e-02,  5.0513e-01,  ...,  3.6386e-01,\n",
       "           -3.5559e-01,  2.6338e-01],\n",
       "          [-7.9691e-01,  1.4400e-02,  1.1308e-01,  ...,  4.1204e-01,\n",
       "           -5.8542e-01,  7.3976e-04],\n",
       "          ...,\n",
       "          [-4.4905e-01,  2.5204e-01, -6.3295e-02,  ...,  1.1924e-01,\n",
       "           -1.7559e-01, -1.0269e-01],\n",
       "          [ 1.7518e-01, -5.7403e-02,  5.2628e-01,  ...,  1.3602e-01,\n",
       "            2.7294e-01,  4.6709e-01],\n",
       "          [ 2.6942e-01,  5.7534e-01,  1.3846e-01,  ...,  1.9228e-01,\n",
       "           -7.8204e-03,  4.3742e-03]],\n",
       " \n",
       "         [[ 2.1363e-02,  4.1721e-02,  2.1647e-02,  ...,  1.2241e-01,\n",
       "            1.1933e-01,  2.1628e-02],\n",
       "          [-6.0956e-01,  3.1282e-02,  5.0558e-01,  ...,  3.1390e-01,\n",
       "           -4.1967e-01,  2.3952e-01],\n",
       "          [-7.9669e-01,  1.3913e-02,  1.1340e-01,  ...,  3.4837e-01,\n",
       "           -6.4286e-01, -2.0755e-02],\n",
       "          ...,\n",
       "          [-4.4917e-01,  2.5187e-01, -6.3214e-02,  ...,  2.0451e-03,\n",
       "           -4.8271e-01, -1.8741e-01],\n",
       "          [-8.7892e-02, -5.4537e-02, -1.7088e-01,  ..., -5.9077e-02,\n",
       "            1.2289e-02,  2.1559e-02],\n",
       "          [ 2.6425e-01,  6.1584e-01,  1.7467e-01,  ...,  1.9251e-01,\n",
       "           -7.6618e-03,  3.9020e-03]]]),\n",
       " tensor([[[ 0.0663,  0.1226,  0.0148,  ...,  0.4327,  0.5719, -0.5052],\n",
       "          [-0.9677,  0.0779,  0.5639,  ...,  0.5390, -0.8202,  0.3815],\n",
       "          [-0.6012, -0.1934,  0.6397,  ...,  1.2898, -0.6257,  0.2568],\n",
       "          ...,\n",
       "          [-0.4924,  0.1592,  0.0620,  ...,  0.2723, -0.3069,  0.4320],\n",
       "          [-0.2654, -0.7308,  0.5435,  ...,  0.6040, -0.0943,  0.8879],\n",
       "          [ 0.2885,  0.5083,  0.2705,  ...,  0.3433,  0.1726, -0.2895]],\n",
       " \n",
       "         [[ 0.0697,  0.1185,  0.0166,  ...,  0.3702,  0.6425, -0.5274],\n",
       "          [-0.9708,  0.0763,  0.5619,  ...,  0.6292, -0.6811,  0.3297],\n",
       "          [-0.6026, -0.1957,  0.6391,  ...,  1.3441, -0.5462,  0.1989],\n",
       "          ...,\n",
       "          [-0.4923,  0.1607,  0.0623,  ...,  0.6119, -0.1056, -0.0969],\n",
       "          [ 0.4584, -0.3650,  0.2389,  ...,  0.6594,  0.3202,  0.7786],\n",
       "          [ 0.2521,  0.4443,  0.3358,  ...,  0.3486,  0.1743, -0.2898]],\n",
       " \n",
       "         [[ 0.0709,  0.1241,  0.0153,  ...,  0.4378,  0.5730, -0.5560],\n",
       "          [-0.9688,  0.0772,  0.5626,  ...,  0.5628, -0.8244,  0.3687],\n",
       "          [-0.6012, -0.1972,  0.6378,  ...,  1.1838, -0.4354,  0.2536],\n",
       "          ...,\n",
       "          [-0.4885,  0.1604,  0.0585,  ..., -0.0467, -0.1407,  0.1805],\n",
       "          [-0.2916, -0.2204,  0.1014,  ..., -0.0277,  0.7852,  0.2520],\n",
       "          [ 0.1044,  0.4919,  0.2856,  ...,  0.3420,  0.1707, -0.2924]]])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output activations from the internal BiLM\n",
    "print(activations[0].shape)\n",
    "bilm_lstm(tokenized_sequences)[\"activations\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## biLM HuggingFace Port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.7004e-02, -5.8437e-03,  3.8740e-02,  ...,  1.1279e-01,\n",
       "            8.2891e-02,  3.0009e-02],\n",
       "          [-9.0796e-01, -1.6039e-01,  8.3736e-01,  ...,  4.3962e-01,\n",
       "           -1.0700e-01,  2.9674e-01],\n",
       "          [-6.9313e-01,  1.0666e-02,  3.2420e-01,  ...,  3.0632e-01,\n",
       "           -3.9687e-01, -1.9246e-02],\n",
       "          ...,\n",
       "          [-4.8125e-01,  1.9718e-01,  3.3368e-03,  ...,  2.3145e-01,\n",
       "           -3.2376e-02, -2.3980e-01],\n",
       "          [ 1.3262e-01, -1.0354e-01,  7.3106e-01,  ...,  6.5551e-01,\n",
       "           -3.6035e-01,  1.1051e+00],\n",
       "          [ 2.4790e-01,  5.9119e-01,  1.9945e-01,  ...,  1.6856e-01,\n",
       "           -3.2241e-02,  4.7876e-02]],\n",
       "\n",
       "         [[ 2.7004e-02, -5.8437e-03,  3.8740e-02,  ...,  1.1832e-01,\n",
       "            9.5615e-02,  2.6538e-02],\n",
       "          [-9.0796e-01, -1.6039e-01,  8.3736e-01,  ...,  4.0804e-01,\n",
       "            7.6256e-03,  3.4817e-01],\n",
       "          [-6.9313e-01,  1.0666e-02,  3.2420e-01,  ...,  2.6200e-01,\n",
       "           -2.6565e-01,  9.1764e-02],\n",
       "          ...,\n",
       "          [-4.8125e-01,  1.9718e-01,  3.3368e-03,  ...,  1.6851e-01,\n",
       "            4.6084e-04, -1.9007e-01],\n",
       "          [ 2.2406e-01, -9.6155e-02,  5.7209e-01,  ...,  3.5383e-01,\n",
       "            3.4999e-01,  1.1917e+00],\n",
       "          [ 2.6819e-01,  5.4052e-01,  1.6110e-01,  ...,  1.6856e-01,\n",
       "           -3.2241e-02,  4.7876e-02]],\n",
       "\n",
       "         [[ 2.7004e-02, -5.8437e-03,  3.8740e-02,  ...,  1.1853e-01,\n",
       "            1.0911e-01,  3.0840e-02],\n",
       "          [-9.0796e-01, -1.6039e-01,  8.3736e-01,  ...,  3.4163e-01,\n",
       "           -8.7206e-02,  1.3587e-01],\n",
       "          [-6.9313e-01,  1.0666e-02,  3.2420e-01,  ...,  2.9988e-01,\n",
       "           -4.1188e-01, -9.2522e-03],\n",
       "          ...,\n",
       "          [-4.8125e-01,  1.9718e-01,  3.3370e-03,  ...,  1.1274e-01,\n",
       "           -3.9837e-01, -3.1559e-01],\n",
       "          [-8.6822e-02, -9.0886e-02, -1.0975e-01,  ..., -9.3278e-01,\n",
       "           -3.8109e-01,  3.3712e-01],\n",
       "          [ 2.6733e-01,  5.6969e-01,  1.9910e-01,  ...,  1.6856e-01,\n",
       "           -3.2241e-02,  4.7876e-02]]],\n",
       "\n",
       "\n",
       "        [[[-6.2272e-01,  1.0484e+00,  4.0326e-01,  ...,  4.7047e-01,\n",
       "            6.6932e-01, -4.9839e-01],\n",
       "          [-1.6019e+00,  3.7537e-02,  7.7758e-01,  ...,  7.2207e-01,\n",
       "           -3.5710e-01,  5.4193e-01],\n",
       "          [-1.1799e+00, -2.1165e-01,  7.8798e-01,  ...,  8.8470e-01,\n",
       "           -1.9626e-01,  1.5248e-01],\n",
       "          ...,\n",
       "          [-5.7446e-01,  3.6304e-02,  1.2496e-01,  ...,  2.6097e+00,\n",
       "            1.3232e+00, -1.9620e-01],\n",
       "          [-4.8998e-01, -9.6392e-01,  6.7778e-01,  ...,  5.4724e-01,\n",
       "           -2.2767e-01,  3.1606e-01],\n",
       "          [ 2.7566e-01,  4.5922e-01,  3.0387e-01,  ..., -9.7192e-01,\n",
       "            1.1762e+00, -8.9182e-01]],\n",
       "\n",
       "         [[-6.2272e-01,  1.0484e+00,  4.0326e-01,  ...,  4.6909e-01,\n",
       "            7.8236e-01, -5.0218e-01],\n",
       "          [-1.6019e+00,  3.7537e-02,  7.7758e-01,  ...,  9.3194e-01,\n",
       "           -1.2589e-01,  7.0056e-01],\n",
       "          [-1.1799e+00, -2.1165e-01,  7.8798e-01,  ...,  1.2088e+00,\n",
       "            2.4461e-01,  4.8569e-01],\n",
       "          ...,\n",
       "          [-5.7446e-01,  3.6304e-02,  1.2496e-01,  ...,  2.7437e+00,\n",
       "            1.4775e+00,  6.0718e-02],\n",
       "          [ 1.5692e-01, -4.9449e-01,  3.5820e-01,  ..., -6.2405e-02,\n",
       "            9.3344e-03,  6.2345e-01],\n",
       "          [ 1.9662e-01,  3.7935e-01,  3.7759e-01,  ..., -9.7192e-01,\n",
       "            1.1762e+00, -8.9182e-01]],\n",
       "\n",
       "         [[-6.2272e-01,  1.0484e+00,  4.0326e-01,  ...,  5.0642e-01,\n",
       "            5.2667e-01, -5.1742e-01],\n",
       "          [-1.6019e+00,  3.7537e-02,  7.7758e-01,  ...,  6.3762e-01,\n",
       "           -3.4186e-01,  2.6141e-01],\n",
       "          [-1.1799e+00, -2.1165e-01,  7.8798e-01,  ...,  1.1889e+00,\n",
       "            3.8806e-02,  4.3814e-01],\n",
       "          ...,\n",
       "          [-5.7446e-01,  3.6304e-02,  1.2496e-01,  ...,  1.5938e+00,\n",
       "           -7.2718e-02, -8.8456e-01],\n",
       "          [-5.6838e-01, -4.2851e-01,  2.1149e-01,  ..., -3.6185e-01,\n",
       "           -4.4196e-02,  4.6017e-01],\n",
       "          [ 5.9267e-02,  4.2960e-01,  3.1142e-01,  ..., -9.7192e-01,\n",
       "            1.1762e+00, -8.9182e-01]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ElmoBiLMTokenizer(PreTrainedTokenizer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.elmo_tokenizer = ElmoTokenizer()\n",
    "        self.token_embedder = ElmoModel.from_pretrained(\"elmo\").elmo_model._elmo_lstm._token_embedder\n",
    "\n",
    "    def __call__(self, text, return_tensors, truncation):\n",
    "        tokenized_text = self.elmo_tokenizer(text, return_tensors, truncation)\n",
    "        embeddings = self.token_embedder(tokenized_text)\n",
    "        return embeddings\n",
    "        \n",
    "    @staticmethod\n",
    "    def from_pretrained(path):\n",
    "        return ElmoBiLMTokenizer()\n",
    "\n",
    "\n",
    "class ElmoBiLMConfig(PretrainedConfig):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_size = 1024\n",
    "        self.num_hidden_layers = 2\n",
    "        self.is_encoder_decoder = False\n",
    "\n",
    "    \n",
    "class ElmoBiLM(PreTrainedModel):\n",
    "    def __init__(self):\n",
    "        super().__init__(config=ElmoBiLMConfig())\n",
    "        self.elmo_lstm = ElmoModel.from_pretrained(\"elmo\").elmo_model._elmo_lstm._elmo_lstm\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        inputs = input_ids\n",
    "        return self.elmo_lstm(inputs=input_ids, mask=attention_mask)\n",
    "\n",
    "bilm_tokenizer = ElmoBiLMTokenizer()\n",
    "tokenizer_batch = bilm_tokenizer(sequences, return_tensors=\"pt\", truncation=True)\n",
    "bilm_model = ElmoBiLM()\n",
    "hidden_states = bilm_model(tokenizer_batch[\"token_embedding\"], attention_mask=tokenizer_batch[\"mask\"])\n",
    "hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 9, 1024])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyle-rnn-experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
