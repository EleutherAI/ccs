{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8412, -0.1165,  0.5267,  ...,  0.4512, -0.1392,  0.2720],\n",
       "         [-0.6446, -0.0498,  0.3769,  ...,  0.4740, -0.1965,  0.0583],\n",
       "         [-0.2392,  1.1553,  0.1504,  ..., -0.0441, -0.4352,  0.2593],\n",
       "         ...,\n",
       "         [-0.3401, -0.1522,  0.0504,  ...,  0.1691, -0.0028, -0.2495],\n",
       "         [-0.1372,  0.0519,  0.0663,  ...,  1.1651,  0.6015, -0.1530],\n",
       "         [-0.2489, -0.0674,  0.5087,  ...,  0.5525, -0.2275,  0.5592]],\n",
       "\n",
       "        [[-0.8412, -0.1165,  0.5267,  ...,  0.5106, -0.0239,  0.3420],\n",
       "         [-0.6446, -0.0498,  0.3769,  ...,  0.5673, -0.0058,  0.2063],\n",
       "         [-0.2392,  1.1553,  0.1504,  ..., -0.0058, -0.2897,  0.3701],\n",
       "         ...,\n",
       "         [-0.3401, -0.1522,  0.0504,  ...,  0.1757, -0.0016,  0.1202],\n",
       "         [-0.1372,  0.0519,  0.0663,  ...,  1.1888,  0.6638, -0.0508],\n",
       "         [ 0.0425,  0.0044,  0.2477,  ...,  0.1274, -0.0031,  0.7462]],\n",
       "\n",
       "        [[-0.8412, -0.1165,  0.5267,  ...,  0.3903, -0.1275,  0.1248],\n",
       "         [-0.6446, -0.0498,  0.3769,  ...,  0.5733, -0.1232,  0.1568],\n",
       "         [-0.2392,  1.1553,  0.1504,  ..., -0.0492, -0.3304,  0.2268],\n",
       "         ...,\n",
       "         [-0.3401, -0.1522,  0.0504,  ...,  0.0765, -0.1440, -0.2627],\n",
       "         [-0.1372,  0.0519,  0.0663,  ...,  0.7869,  0.0141, -0.4077],\n",
       "         [-0.2643, -0.2749, -0.1378,  ..., -0.1953, -0.0320,  0.1377]]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from sacremoses import MosesTokenizer\n",
    "from transformers import (\n",
    "    PretrainedConfig,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "class ElmoConfig(PretrainedConfig):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_size = 1024\n",
    "        self.num_hidden_layers = 1\n",
    "        self.is_encoder_decoder = False\n",
    "\n",
    "\n",
    "class ElmoModel(PreTrainedModel):\n",
    "    def __init__(self, options_file, weights_file):\n",
    "        super().__init__(config=ElmoConfig())\n",
    "        self.elmo_model = Elmo(options_file, weights_file, 1, dropout=0)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        return self.elmo_model(input_ids)[\"elmo_representations\"][0]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_pretrained(path):\n",
    "        options_file = (\n",
    "            \"/home/kyle/elk/elk/rnn/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\"\n",
    "        )\n",
    "        weights_file = (\n",
    "            \"/home/kyle/elk/elk/rnn/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\"\n",
    "        )\n",
    "        return ElmoModel(options_file, weights_file)\n",
    "\n",
    "\n",
    "class ElmoTokenizer(PreTrainedTokenizer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.tokenizer = MosesTokenizer()\n",
    "\n",
    "    def __call__(self, text, return_tensors, truncation):\n",
    "        sequences = text if isinstance(text, list) else [text]\n",
    "        tokens = [\n",
    "            self.tokenizer.tokenize(sequence, escape=False) for sequence in sequences\n",
    "        ]\n",
    "        character_ids = batch_to_ids(tokens)  # type: ignore\n",
    "        return character_ids\n",
    "\n",
    "    @staticmethod\n",
    "    def from_pretrained(path):\n",
    "        return ElmoTokenizer()\n",
    "\n",
    "sequences = [\"Is this an ELMo representation? Yes\", \"Is this an ELMo representation? No\", \"Is this an ELMo representation? Maybe\"]\n",
    "elmo_tokenizer = ElmoTokenizer()\n",
    "tokenized_sequences = elmo_tokenizer(sequences, return_tensors=\"pt\", truncation=True)\n",
    "elmo_model = ElmoModel.from_pretrained(\"elmo\")\n",
    "embeddings = elmo_model(tokenized_sequences)\n",
    "print(embeddings.shape)\n",
    "embeddings\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 9, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mask': tensor([[True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True]]),\n",
       " 'token_embedding': tensor([[[-8.5709e+00, -9.9289e+00,  4.0575e+00,  ...,  9.1735e+00,\n",
       "            8.3215e+00, -6.9233e+00],\n",
       "          [-1.3800e-02, -2.2660e-01, -3.4851e-02,  ...,  1.9179e-01,\n",
       "            4.6514e-02, -2.2795e-02],\n",
       "          [-6.0722e-02,  5.1529e-02,  1.8452e-02,  ...,  2.3105e-01,\n",
       "            3.6155e-03,  4.1534e-02],\n",
       "          ...,\n",
       "          [ 6.4416e-01, -7.7645e-02,  7.0715e-02,  ...,  6.5416e-01,\n",
       "            5.1353e-01, -2.2917e-02],\n",
       "          [-3.8933e-01,  8.6538e-01,  1.1729e-01,  ...,  4.5468e-01,\n",
       "           -9.4481e-02,  2.5647e-01],\n",
       "          [-1.2410e-01, -3.2147e+00, -6.1114e+00,  ...,  9.8041e+00,\n",
       "            1.9380e+00, -8.1160e+00]],\n",
       " \n",
       "         [[-8.5709e+00, -9.9289e+00,  4.0575e+00,  ...,  9.1735e+00,\n",
       "            8.3215e+00, -6.9233e+00],\n",
       "          [-1.3800e-02, -2.2660e-01, -3.4851e-02,  ...,  1.9179e-01,\n",
       "            4.6514e-02, -2.2795e-02],\n",
       "          [-6.0722e-02,  5.1529e-02,  1.8452e-02,  ...,  2.3105e-01,\n",
       "            3.6155e-03,  4.1534e-02],\n",
       "          ...,\n",
       "          [ 6.4416e-01, -7.7645e-02,  7.0715e-02,  ...,  6.5416e-01,\n",
       "            5.1353e-01, -2.2917e-02],\n",
       "          [-2.5356e-01,  6.0378e-01, -1.8716e-01,  ...,  9.0713e-02,\n",
       "           -3.6864e-01,  4.2334e-01],\n",
       "          [-1.2410e-01, -3.2147e+00, -6.1114e+00,  ...,  9.8041e+00,\n",
       "            1.9380e+00, -8.1160e+00]],\n",
       " \n",
       "         [[-8.5709e+00, -9.9289e+00,  4.0575e+00,  ...,  9.1735e+00,\n",
       "            8.3215e+00, -6.9233e+00],\n",
       "          [-1.3800e-02, -2.2660e-01, -3.4851e-02,  ...,  1.9179e-01,\n",
       "            4.6514e-02, -2.2795e-02],\n",
       "          [-6.0722e-02,  5.1529e-02,  1.8452e-02,  ...,  2.3105e-01,\n",
       "            3.6155e-03,  4.1534e-02],\n",
       "          ...,\n",
       "          [ 6.4416e-01, -7.7645e-02,  7.0715e-02,  ...,  6.5416e-01,\n",
       "            5.1353e-01, -2.2917e-02],\n",
       "          [-1.3765e-01, -3.0527e-01, -5.1513e-01,  ...,  7.0863e-01,\n",
       "            3.2935e-01, -3.8413e-01],\n",
       "          [-1.2410e-01, -3.2147e+00, -6.1114e+00,  ...,  9.8041e+00,\n",
       "            1.9380e+00, -8.1160e+00]]])}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilm_lstm = elmo_model.elmo_model._elmo_lstm\n",
    "lstm_token_embedder = bilm_lstm._token_embedder\n",
    "internal_embeddings = lstm_token_embedder(tokenized_sequences)\n",
    "print(internal_embeddings[\"token_embedding\"].shape)\n",
    "internal_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 9, 1024])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = bilm_lstm(tokenized_sequences)[\"activations\"]\n",
    "activations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 9, 1024])\n",
      "512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0179,  0.0713,  0.0110,  ...,  0.1264,  0.1231,  0.0258],\n",
       "          [-0.4891,  0.1080,  0.3984,  ...,  0.3566, -0.3906,  0.2677],\n",
       "          [-0.6844,  0.0765,  0.0339,  ...,  0.3921, -0.6338,  0.0184],\n",
       "          ...,\n",
       "          [-0.3669,  0.2947, -0.0701,  ...,  0.1141, -0.2551,  0.0222],\n",
       "          [ 0.0987,  0.0519,  0.5976,  ...,  0.3036,  0.1679,  0.4183],\n",
       "          [ 0.2429,  0.6859,  0.1255,  ...,  0.1900, -0.0090,  0.0093]],\n",
       "\n",
       "         [[ 0.0178,  0.0720,  0.0108,  ...,  0.1288,  0.1253,  0.0255],\n",
       "          [-0.4869,  0.1092,  0.3964,  ...,  0.3726, -0.3611,  0.2696],\n",
       "          [-0.6809,  0.0774,  0.0320,  ...,  0.4158, -0.5869,  0.0081],\n",
       "          ...,\n",
       "          [-0.3650,  0.2953, -0.0698,  ...,  0.1185, -0.1778, -0.0985],\n",
       "          [ 0.1864, -0.0251,  0.4565,  ...,  0.1383,  0.2780,  0.4876],\n",
       "          [ 0.2692,  0.6085,  0.1256,  ...,  0.1899, -0.0089,  0.0096]],\n",
       "\n",
       "         [[ 0.0178,  0.0718,  0.0108,  ...,  0.1197,  0.1168,  0.0254],\n",
       "          [-0.4874,  0.1090,  0.3969,  ...,  0.3162, -0.4267,  0.2412],\n",
       "          [-0.6814,  0.0768,  0.0324,  ...,  0.3482, -0.6398, -0.0201],\n",
       "          ...,\n",
       "          [-0.3654,  0.2952, -0.0699,  ..., -0.0029, -0.5042, -0.1853],\n",
       "          [-0.0613, -0.0015, -0.1986,  ..., -0.0825,  0.0153,  0.0278],\n",
       "          [ 0.2533,  0.6493,  0.1590,  ...,  0.1901, -0.0090,  0.0091]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0665,  0.1540,  0.0090,  ...,  0.4285,  0.5710, -0.5000],\n",
       "          [-1.0333,  0.0447,  0.4967,  ...,  0.5364, -0.8225,  0.3649],\n",
       "          [-0.6076, -0.2074,  0.6772,  ...,  1.2947, -0.6323,  0.2308],\n",
       "          ...,\n",
       "          [-0.4031,  0.2274,  0.0676,  ...,  0.2643, -0.2998,  0.4091],\n",
       "          [-0.1688, -0.6842,  0.5074,  ...,  0.6033, -0.0981,  0.8906],\n",
       "          [ 0.2750,  0.5564,  0.2835,  ...,  0.3424,  0.1711, -0.2883]],\n",
       "\n",
       "         [[ 0.0698,  0.1484,  0.0119,  ...,  0.3645,  0.6451, -0.5217],\n",
       "          [-1.0366,  0.0436,  0.4954,  ...,  0.6318, -0.6794,  0.3095],\n",
       "          [-0.6073, -0.2084,  0.6785,  ...,  1.3486, -0.5509,  0.1711],\n",
       "          ...,\n",
       "          [-0.4015,  0.2295,  0.0682,  ...,  0.6103, -0.1129, -0.1293],\n",
       "          [ 0.5394, -0.3947,  0.2887,  ...,  0.6495,  0.3035,  0.7798],\n",
       "          [ 0.2528,  0.4884,  0.3602,  ...,  0.3474,  0.1730, -0.2880]],\n",
       "\n",
       "         [[ 0.0718,  0.1548,  0.0116,  ...,  0.4308,  0.5664, -0.5516],\n",
       "          [-1.0346,  0.0450,  0.4965,  ...,  0.5641, -0.8276,  0.3495],\n",
       "          [-0.6060, -0.2098,  0.6765,  ...,  1.1998, -0.4311,  0.2178],\n",
       "          ...,\n",
       "          [-0.3974,  0.2289,  0.0636,  ..., -0.0603, -0.1377,  0.1384],\n",
       "          [-0.2145, -0.2063,  0.0920,  ..., -0.0522,  0.7941,  0.2501],\n",
       "          [ 0.0961,  0.5441,  0.2953,  ...,  0.3413,  0.1688, -0.2907]]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internal_bilm = bilm_lstm._elmo_lstm\n",
    "bilm_hidden_states = internal_bilm(inputs=internal_embeddings[\"token_embedding\"], mask=internal_embeddings[\"mask\"])\n",
    "print(bilm_hidden_states.shape)\n",
    "print(internal_bilm.hidden_size)\n",
    "\n",
    "# Calling the internal BiLM directly gives the hidden states for each layer. There are two layers.\n",
    "# The output tensor is of shape (2, batch_size, sequence_length, 1012 (512 * 2?))\n",
    "bilm_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0183, 0.0676, 0.0123,  ..., 0.1266, 0.1232, 0.0253])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilm_hidden_states[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 9, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[[-8.5709e+00, -9.9289e+00,  4.0575e+00,  ...,  9.1735e+00,\n",
       "            8.3215e+00, -6.9233e+00],\n",
       "          [-1.3800e-02, -2.2660e-01, -3.4851e-02,  ...,  1.9179e-01,\n",
       "            4.6514e-02, -2.2795e-02],\n",
       "          [-6.0722e-02,  5.1529e-02,  1.8452e-02,  ...,  2.3105e-01,\n",
       "            3.6155e-03,  4.1534e-02],\n",
       "          ...,\n",
       "          [ 6.4416e-01, -7.7645e-02,  7.0715e-02,  ...,  6.5416e-01,\n",
       "            5.1353e-01, -2.2917e-02],\n",
       "          [-3.8933e-01,  8.6538e-01,  1.1729e-01,  ...,  4.5468e-01,\n",
       "           -9.4481e-02,  2.5647e-01],\n",
       "          [-1.2410e-01, -3.2147e+00, -6.1114e+00,  ...,  9.8041e+00,\n",
       "            1.9380e+00, -8.1160e+00]],\n",
       " \n",
       "         [[-8.5709e+00, -9.9289e+00,  4.0575e+00,  ...,  9.1735e+00,\n",
       "            8.3215e+00, -6.9233e+00],\n",
       "          [-1.3800e-02, -2.2660e-01, -3.4851e-02,  ...,  1.9179e-01,\n",
       "            4.6514e-02, -2.2795e-02],\n",
       "          [-6.0722e-02,  5.1529e-02,  1.8452e-02,  ...,  2.3105e-01,\n",
       "            3.6155e-03,  4.1534e-02],\n",
       "          ...,\n",
       "          [ 6.4416e-01, -7.7645e-02,  7.0715e-02,  ...,  6.5416e-01,\n",
       "            5.1353e-01, -2.2917e-02],\n",
       "          [-2.5356e-01,  6.0378e-01, -1.8716e-01,  ...,  9.0713e-02,\n",
       "           -3.6864e-01,  4.2334e-01],\n",
       "          [-1.2410e-01, -3.2147e+00, -6.1114e+00,  ...,  9.8041e+00,\n",
       "            1.9380e+00, -8.1160e+00]],\n",
       " \n",
       "         [[-8.5709e+00, -9.9289e+00,  4.0575e+00,  ...,  9.1735e+00,\n",
       "            8.3215e+00, -6.9233e+00],\n",
       "          [-1.3800e-02, -2.2660e-01, -3.4851e-02,  ...,  1.9179e-01,\n",
       "            4.6514e-02, -2.2795e-02],\n",
       "          [-6.0722e-02,  5.1529e-02,  1.8452e-02,  ...,  2.3105e-01,\n",
       "            3.6155e-03,  4.1534e-02],\n",
       "          ...,\n",
       "          [ 6.4416e-01, -7.7645e-02,  7.0715e-02,  ...,  6.5416e-01,\n",
       "            5.1353e-01, -2.2917e-02],\n",
       "          [-1.3765e-01, -3.0527e-01, -5.1513e-01,  ...,  7.0863e-01,\n",
       "            3.2935e-01, -3.8413e-01],\n",
       "          [-1.2410e-01, -3.2147e+00, -6.1114e+00,  ...,  9.8041e+00,\n",
       "            1.9380e+00, -8.1160e+00]]]),\n",
       " tensor([[[ 0.0188,  0.0630,  0.0140,  ...,  0.1269,  0.1234,  0.0246],\n",
       "          [-0.5190,  0.0891,  0.4232,  ...,  0.3568, -0.3896,  0.2661],\n",
       "          [-0.7234,  0.0586,  0.0545,  ...,  0.3923, -0.6338,  0.0175],\n",
       "          ...,\n",
       "          [-0.3913,  0.2854, -0.0697,  ...,  0.1144, -0.2565,  0.0211],\n",
       "          [ 0.0932,  0.0355,  0.6376,  ...,  0.3029,  0.1673,  0.4148],\n",
       "          [ 0.2446,  0.6776,  0.1312,  ...,  0.1906, -0.0088,  0.0080]],\n",
       " \n",
       "         [[ 0.0188,  0.0637,  0.0138,  ...,  0.1294,  0.1256,  0.0242],\n",
       "          [-0.5167,  0.0903,  0.4209,  ...,  0.3726, -0.3603,  0.2678],\n",
       "          [-0.7205,  0.0595,  0.0525,  ...,  0.4160, -0.5872,  0.0065],\n",
       "          ...,\n",
       "          [-0.3895,  0.2861, -0.0695,  ...,  0.1190, -0.1779, -0.1000],\n",
       "          [ 0.1817, -0.0342,  0.4789,  ...,  0.1382,  0.2772,  0.4838],\n",
       "          [ 0.2697,  0.5977,  0.1287,  ...,  0.1905, -0.0088,  0.0082]],\n",
       " \n",
       "         [[ 0.0188,  0.0635,  0.0138,  ...,  0.1203,  0.1173,  0.0243],\n",
       "          [-0.5172,  0.0902,  0.4214,  ...,  0.3169, -0.4254,  0.2400],\n",
       "          [-0.7208,  0.0589,  0.0529,  ...,  0.3487, -0.6403, -0.0207],\n",
       "          ...,\n",
       "          [-0.3898,  0.2860, -0.0695,  ..., -0.0020, -0.5023, -0.1863],\n",
       "          [-0.0695, -0.0187, -0.1936,  ..., -0.0780,  0.0143,  0.0262],\n",
       "          [ 0.2570,  0.6390,  0.1628,  ...,  0.1907, -0.0088,  0.0078]]]),\n",
       " tensor([[[ 0.0663,  0.1454,  0.0107,  ...,  0.4297,  0.5716, -0.5013],\n",
       "          [-1.0224,  0.0508,  0.5135,  ...,  0.5380, -0.8221,  0.3665],\n",
       "          [-0.6127, -0.2148,  0.6633,  ...,  1.2953, -0.6317,  0.2351],\n",
       "          ...,\n",
       "          [-0.4332,  0.2095,  0.0636,  ...,  0.2656, -0.3013,  0.4139],\n",
       "          [-0.2017, -0.6969,  0.5167,  ...,  0.6041, -0.0973,  0.8911],\n",
       "          [ 0.2796,  0.5427,  0.2785,  ...,  0.3427,  0.1713, -0.2887]],\n",
       " \n",
       "         [[ 0.0696,  0.1402,  0.0132,  ...,  0.3658,  0.6450, -0.5231],\n",
       "          [-1.0260,  0.0494,  0.5119,  ...,  0.6331, -0.6803,  0.3121],\n",
       "          [-0.6130, -0.2163,  0.6642,  ...,  1.3502, -0.5505,  0.1760],\n",
       "          ...,\n",
       "          [-0.4319,  0.2116,  0.0641,  ...,  0.6118, -0.1116, -0.1246],\n",
       "          [ 0.5167, -0.3847,  0.2667,  ...,  0.6512,  0.3069,  0.7798],\n",
       "          [ 0.2525,  0.4755,  0.3532,  ...,  0.3478,  0.1731, -0.2885]],\n",
       " \n",
       "         [[ 0.0715,  0.1464,  0.0126,  ...,  0.4326,  0.5677, -0.5528],\n",
       "          [-1.0239,  0.0507,  0.5130,  ...,  0.5651, -0.8268,  0.3515],\n",
       "          [-0.6116, -0.2178,  0.6624,  ...,  1.1986, -0.4316,  0.2233],\n",
       "          ...,\n",
       "          [-0.4280,  0.2112,  0.0598,  ..., -0.0587, -0.1382,  0.1450],\n",
       "          [-0.2401, -0.2105,  0.0931,  ..., -0.0473,  0.7928,  0.2506],\n",
       "          [ 0.0983,  0.5292,  0.2931,  ...,  0.3415,  0.1690, -0.2912]]])]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output activations from the internal BiLM\n",
    "print(activations[0].shape)\n",
    "bilm_lstm(tokenized_sequences)[\"activations\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## biLM HuggingFace Port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.7004e-02, -5.8437e-03,  3.8740e-02,  ...,  1.1279e-01,\n",
       "            8.2891e-02,  3.0009e-02],\n",
       "          [-9.0796e-01, -1.6039e-01,  8.3736e-01,  ...,  4.3962e-01,\n",
       "           -1.0700e-01,  2.9674e-01],\n",
       "          [-6.9313e-01,  1.0666e-02,  3.2420e-01,  ...,  3.0632e-01,\n",
       "           -3.9687e-01, -1.9246e-02],\n",
       "          ...,\n",
       "          [-4.8125e-01,  1.9718e-01,  3.3368e-03,  ...,  2.3145e-01,\n",
       "           -3.2376e-02, -2.3980e-01],\n",
       "          [ 1.3262e-01, -1.0354e-01,  7.3106e-01,  ...,  6.5551e-01,\n",
       "           -3.6035e-01,  1.1051e+00],\n",
       "          [ 2.4790e-01,  5.9119e-01,  1.9945e-01,  ...,  1.6856e-01,\n",
       "           -3.2241e-02,  4.7876e-02]],\n",
       "\n",
       "         [[ 2.7004e-02, -5.8437e-03,  3.8740e-02,  ...,  1.1832e-01,\n",
       "            9.5615e-02,  2.6538e-02],\n",
       "          [-9.0796e-01, -1.6039e-01,  8.3736e-01,  ...,  4.0804e-01,\n",
       "            7.6256e-03,  3.4817e-01],\n",
       "          [-6.9313e-01,  1.0666e-02,  3.2420e-01,  ...,  2.6200e-01,\n",
       "           -2.6565e-01,  9.1764e-02],\n",
       "          ...,\n",
       "          [-4.8125e-01,  1.9718e-01,  3.3368e-03,  ...,  1.6851e-01,\n",
       "            4.6084e-04, -1.9007e-01],\n",
       "          [ 2.2406e-01, -9.6155e-02,  5.7209e-01,  ...,  3.5383e-01,\n",
       "            3.4999e-01,  1.1917e+00],\n",
       "          [ 2.6819e-01,  5.4052e-01,  1.6110e-01,  ...,  1.6856e-01,\n",
       "           -3.2241e-02,  4.7876e-02]],\n",
       "\n",
       "         [[ 2.7004e-02, -5.8437e-03,  3.8740e-02,  ...,  1.1853e-01,\n",
       "            1.0911e-01,  3.0840e-02],\n",
       "          [-9.0796e-01, -1.6039e-01,  8.3736e-01,  ...,  3.4163e-01,\n",
       "           -8.7206e-02,  1.3587e-01],\n",
       "          [-6.9313e-01,  1.0666e-02,  3.2420e-01,  ...,  2.9988e-01,\n",
       "           -4.1188e-01, -9.2522e-03],\n",
       "          ...,\n",
       "          [-4.8125e-01,  1.9718e-01,  3.3370e-03,  ...,  1.1274e-01,\n",
       "           -3.9837e-01, -3.1559e-01],\n",
       "          [-8.6822e-02, -9.0886e-02, -1.0975e-01,  ..., -9.3278e-01,\n",
       "           -3.8109e-01,  3.3712e-01],\n",
       "          [ 2.6733e-01,  5.6969e-01,  1.9910e-01,  ...,  1.6856e-01,\n",
       "           -3.2241e-02,  4.7876e-02]]],\n",
       "\n",
       "\n",
       "        [[[-6.2272e-01,  1.0484e+00,  4.0326e-01,  ...,  4.7047e-01,\n",
       "            6.6932e-01, -4.9839e-01],\n",
       "          [-1.6019e+00,  3.7537e-02,  7.7758e-01,  ...,  7.2207e-01,\n",
       "           -3.5710e-01,  5.4193e-01],\n",
       "          [-1.1799e+00, -2.1165e-01,  7.8798e-01,  ...,  8.8470e-01,\n",
       "           -1.9626e-01,  1.5248e-01],\n",
       "          ...,\n",
       "          [-5.7446e-01,  3.6304e-02,  1.2496e-01,  ...,  2.6097e+00,\n",
       "            1.3232e+00, -1.9620e-01],\n",
       "          [-4.8998e-01, -9.6392e-01,  6.7778e-01,  ...,  5.4724e-01,\n",
       "           -2.2767e-01,  3.1606e-01],\n",
       "          [ 2.7566e-01,  4.5922e-01,  3.0387e-01,  ..., -9.7192e-01,\n",
       "            1.1762e+00, -8.9182e-01]],\n",
       "\n",
       "         [[-6.2272e-01,  1.0484e+00,  4.0326e-01,  ...,  4.6909e-01,\n",
       "            7.8236e-01, -5.0218e-01],\n",
       "          [-1.6019e+00,  3.7537e-02,  7.7758e-01,  ...,  9.3194e-01,\n",
       "           -1.2589e-01,  7.0056e-01],\n",
       "          [-1.1799e+00, -2.1165e-01,  7.8798e-01,  ...,  1.2088e+00,\n",
       "            2.4461e-01,  4.8569e-01],\n",
       "          ...,\n",
       "          [-5.7446e-01,  3.6304e-02,  1.2496e-01,  ...,  2.7437e+00,\n",
       "            1.4775e+00,  6.0718e-02],\n",
       "          [ 1.5692e-01, -4.9449e-01,  3.5820e-01,  ..., -6.2405e-02,\n",
       "            9.3344e-03,  6.2345e-01],\n",
       "          [ 1.9662e-01,  3.7935e-01,  3.7759e-01,  ..., -9.7192e-01,\n",
       "            1.1762e+00, -8.9182e-01]],\n",
       "\n",
       "         [[-6.2272e-01,  1.0484e+00,  4.0326e-01,  ...,  5.0642e-01,\n",
       "            5.2667e-01, -5.1742e-01],\n",
       "          [-1.6019e+00,  3.7537e-02,  7.7758e-01,  ...,  6.3762e-01,\n",
       "           -3.4186e-01,  2.6141e-01],\n",
       "          [-1.1799e+00, -2.1165e-01,  7.8798e-01,  ...,  1.1889e+00,\n",
       "            3.8806e-02,  4.3814e-01],\n",
       "          ...,\n",
       "          [-5.7446e-01,  3.6304e-02,  1.2496e-01,  ...,  1.5938e+00,\n",
       "           -7.2718e-02, -8.8456e-01],\n",
       "          [-5.6838e-01, -4.2851e-01,  2.1149e-01,  ..., -3.6185e-01,\n",
       "           -4.4196e-02,  4.6017e-01],\n",
       "          [ 5.9267e-02,  4.2960e-01,  3.1142e-01,  ..., -9.7192e-01,\n",
       "            1.1762e+00, -8.9182e-01]]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ElmoBiLMTokenizer(PreTrainedTokenizer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.elmo_tokenizer = ElmoTokenizer()\n",
    "        self.token_embedder = ElmoModel.from_pretrained(\"elmo\").elmo_model._elmo_lstm._token_embedder\n",
    "\n",
    "    def __call__(self, text, return_tensors, truncation):\n",
    "        tokenized_text = self.elmo_tokenizer(text, return_tensors, truncation)\n",
    "        embeddings = self.token_embedder(tokenized_text)\n",
    "        return embeddings\n",
    "        \n",
    "    @staticmethod\n",
    "    def from_pretrained(path):\n",
    "        return ElmoBiLMTokenizer()\n",
    "\n",
    "\n",
    "class ElmoBiLMConfig(PretrainedConfig):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_size = 1024\n",
    "        self.num_hidden_layers = 2\n",
    "        self.is_encoder_decoder = False\n",
    "\n",
    "    \n",
    "class ElmoBiLM(PreTrainedModel):\n",
    "    def __init__(self):\n",
    "        super().__init__(config=ElmoBiLMConfig())\n",
    "        self.elmo_lstm = ElmoModel.from_pretrained(\"elmo\").elmo_model._elmo_lstm._elmo_lstm\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        inputs = input_ids\n",
    "        return self.elmo_lstm(inputs=input_ids, mask=attention_mask)\n",
    "\n",
    "bilm_tokenizer = ElmoBiLMTokenizer()\n",
    "tokenizer_batch = bilm_tokenizer(sequences, return_tensors=\"pt\", truncation=True)\n",
    "bilm_model = ElmoBiLM()\n",
    "hidden_states = bilm_model(tokenizer_batch[\"token_embedding\"], attention_mask=tokenizer_batch[\"mask\"])\n",
    "hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 9, 1024])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kyle-rnn-experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
