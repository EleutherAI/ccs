{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "from einops import rearrange, repeat\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at EleutherAI/gpt-j-6B were not used when initializing GPTJModel: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing GPTJModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPTJModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"EleutherAI/gpt-j-6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Encode input sequence\n",
    "input_sequence = \"I want to eat a banana\"\n",
    "input_ids = tokenizer.encode(input_sequence, return_tensors=\"pt\")\n",
    "\n",
    "# Generate hidden states\n",
    "outputs = model(input_ids, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "torch.Size([28, 6, 4096])\n"
     ]
    }
   ],
   "source": [
    "hidden_states = outputs.hidden_states\n",
    "print(len(hidden_states))\n",
    "cat_hidden_states = torch.cat(hidden_states[:-1], dim=0)\n",
    "print(cat_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_stack_layers(num_layers: int, prefix_path: str) -> torch.Tensor:\n",
    "    layers = []\n",
    "    for i in range(num_layers):\n",
    "        layer_path = f\"{prefix_path}/layer_{i}.pt\"\n",
    "        layer = torch.load(layer_path)\n",
    "        layers.append(layer.weight.cpu())\n",
    "    stacked = torch.cat(layers, dim=0)\n",
    "    return stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/waree/elk-reporters/EleutherAI/gpt-j-6b/sethapun/arithmetic_2as_1to1/busy-kapitsa/reporters'\n",
    "rep_weights = load_and_stack_layers(model.config.n_layer,path)\n",
    "print(rep_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 6])\n"
     ]
    }
   ],
   "source": [
    "# Use einsum to do multiplication \n",
    "\n",
    "result = torch.einsum('bse,be->bs', cat_hidden_states, rep_weights)\n",
    "print(result.shape)\n",
    "\n",
    "sigmoid_result = torch.sigmoid(result)\n",
    "softmax_result = torch.softmax(result, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-8.55e-05,  1.82e-03,  1.37e-03,  2.04e-02,  6.52e-03,  2.09e-02],\n",
      "        [ 3.09e+00,  3.28e+00,  3.31e+00,  2.91e+00,  4.03e+00,  4.02e+00],\n",
      "        [ 3.01e-01,  1.41e-02, -8.31e-02,  4.20e-01,  3.41e-01, -4.00e-01],\n",
      "        [ 2.40e+01, -8.44e-01, -1.08e+00, -1.11e+00, -4.59e-01, -1.89e+00],\n",
      "        [ 1.37e+02, -4.33e-02, -7.48e-02,  4.54e-01, -1.43e-02,  8.36e-02],\n",
      "        [ 4.35e+02,  2.76e+00,  1.94e+00,  3.26e+00,  2.61e+00,  3.57e+00],\n",
      "        [-3.40e+02, -2.66e+00, -1.91e+00, -3.20e+00, -1.77e+00, -3.45e+00],\n",
      "        [-2.24e+02, -1.06e+00, -9.89e-01, -1.47e+00, -7.43e-01, -6.54e-01],\n",
      "        [ 4.56e+02,  5.52e+00,  4.37e+00,  5.68e+00,  4.68e+00,  5.77e+00],\n",
      "        [ 3.73e+02,  4.09e+00,  3.54e+00,  5.42e+00,  3.82e+00,  4.84e+00],\n",
      "        [ 4.73e+02,  7.24e+00,  6.92e+00,  7.82e+00,  6.66e+00,  7.46e+00],\n",
      "        [ 3.18e+02,  5.63e+00,  5.18e+00,  6.15e+00,  5.58e+00,  6.15e+00],\n",
      "        [-4.56e+01, -2.00e+00, -2.19e+00, -2.44e+00, -2.22e+00, -3.11e+00],\n",
      "        [ 6.62e+01,  4.23e-01,  3.37e-01,  4.16e-01,  9.71e-01,  1.84e-01],\n",
      "        [ 4.70e-01,  6.14e-01,  2.17e-01,  8.59e-04, -6.30e-01,  8.65e-01],\n",
      "        [-2.68e+01,  1.23e+00,  1.17e+00,  1.48e+00,  1.71e+00, -6.69e-01],\n",
      "        [ 2.41e+02,  4.53e+00,  5.32e+00,  5.09e+00,  3.30e+00,  5.23e+00],\n",
      "        [ 5.63e+02,  1.42e+01,  1.57e+01,  1.41e+01,  1.21e+01,  1.57e+01],\n",
      "        [ 6.10e+02,  2.17e+01,  2.33e+01,  2.03e+01,  1.79e+01,  1.83e+01],\n",
      "        [ 4.87e+02,  2.49e+01,  2.40e+01,  2.20e+01,  2.07e+01,  1.90e+01],\n",
      "        [ 5.33e+02,  3.22e+01,  3.10e+01,  2.79e+01,  2.66e+01,  2.46e+01],\n",
      "        [ 5.09e+02,  3.86e+01,  3.61e+01,  3.38e+01,  3.23e+01,  2.90e+01],\n",
      "        [ 4.96e+02,  4.37e+01,  4.07e+01,  3.69e+01,  3.53e+01,  2.94e+01],\n",
      "        [ 4.17e+02,  4.14e+01,  3.84e+01,  3.43e+01,  3.41e+01,  2.84e+01],\n",
      "        [ 4.14e+02,  4.70e+01,  4.43e+01,  3.83e+01,  3.92e+01,  3.13e+01],\n",
      "        [ 8.55e+01,  3.76e+01,  3.58e+01,  3.21e+01,  3.14e+01,  2.42e+01],\n",
      "        [ 4.56e+02,  5.44e+01,  5.15e+01,  4.76e+01,  4.29e+01,  3.96e+01],\n",
      "        [ 4.49e+01,  1.03e+01,  7.92e+00,  7.46e+00,  4.45e+00,  6.23e+00]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6524e-01, 1.6555e-01, 1.6548e-01, 1.6866e-01, 1.6633e-01, 1.6874e-01],\n",
       "        [1.0711e-01, 1.2853e-01, 1.3314e-01, 8.8654e-02, 2.7302e-01, 2.6954e-01],\n",
       "        [1.9625e-01, 1.4730e-01, 1.3366e-01, 2.2112e-01, 2.0433e-01, 9.7341e-02],\n",
       "        [1.0000e+00, 1.6504e-11, 1.3084e-11, 1.2636e-11, 2.4254e-11, 5.8121e-12],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 1.5210e-01, 3.2207e-01, 8.8472e-02, 3.6828e-01, 6.9068e-02],\n",
       "        [0.0000e+00, 1.7877e-01, 1.9123e-01, 1.1812e-01, 2.4455e-01, 2.6733e-01],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [3.3717e-20, 2.7876e-01, 2.2860e-01, 1.7954e-01, 2.2163e-01, 9.1484e-02],\n",
       "        [1.0000e+00, 2.7742e-29, 2.5448e-29, 2.7558e-29, 4.8000e-29, 2.1847e-29],\n",
       "        [1.8614e-01, 2.1494e-01, 1.4443e-01, 1.1638e-01, 6.1961e-02, 2.7615e-01],\n",
       "        [1.3916e-13, 2.0031e-01, 1.8908e-01, 2.5663e-01, 3.2401e-01, 2.9968e-02],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 1.6037e-21, 2.6027e-22, 6.5936e-24, 3.2598e-24, 2.2691e-27],\n",
       "        [1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 9.7532e-16, 8.7810e-17, 5.5431e-17, 2.7475e-18, 1.6325e-17]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## low dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path: Path | str):\n",
    "    \"\"\"Load a reporter from a file.\"\"\"\n",
    "    \n",
    "    return torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = load('/home/waree/elk-reporters/EleutherAI/gpt-j-6b/sethapun/arithmetic_2as_1to1/busy-kapitsa/reporters/layer_20.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 4096])\n",
      "torch.Size([1, 4096])\n"
     ]
    }
   ],
   "source": [
    "hs = hidden_states[20]\n",
    "print(hs.shape)\n",
    "\n",
    "weight = rep.weight.cpu()\n",
    "print(weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[533.0842,  32.2087,  30.9929,  27.9183,  26.5704,  24.5978]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Use einsum to do multiplication \n",
    "\n",
    "result = torch.einsum('bse,be->bs', hs , weight)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[533.0849,  32.2087,  30.9929,  27.9183,  26.5704,  24.5978]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Use einops to do broadcasting first\n",
    "\n",
    "# Use einops.repeat() to make 6 copies of the last dimension\n",
    "weight_repeated = repeat(weight, 'b d -> b c d', c=6)\n",
    "\n",
    "result = torch.einsum('bse,bse->bs', hs , weight_repeated)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 4096])\n",
      "tensor([[[ 0.0003,  0.0007, -0.0002,  ...,  0.0031, -0.0018, -0.0012],\n",
      "         [-0.0050, -0.0097,  0.0032,  ..., -0.0443,  0.0257,  0.0170],\n",
      "         [-0.0019, -0.0037,  0.0012,  ..., -0.0170,  0.0098,  0.0065],\n",
      "         ...,\n",
      "         [-0.0059, -0.0114,  0.0037,  ..., -0.0522,  0.0303,  0.0200],\n",
      "         [ 0.0007,  0.0014, -0.0005,  ...,  0.0066, -0.0038, -0.0025],\n",
      "         [ 0.0019,  0.0037, -0.0012,  ...,  0.0168, -0.0098, -0.0064]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 4096, 4096])\n"
     ]
    }
   ],
   "source": [
    "# Use einops to do broadcasting first then multiply using @\n",
    "\n",
    "# Use einops.repeat() to make 6 copies of the last dimension\n",
    "weight_repeated = repeat(weight, 'b d -> b c d', c=6)\n",
    "print(weight_repeated.shape)\n",
    "\n",
    "result = torch.matmul(hs.mT,weight_repeated)\n",
    "print(result)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: EleutherAI/gpt-j-6B\n",
      "Number of layers: 28\n",
      "Number of hidden units: 4096\n"
     ]
    }
   ],
   "source": [
    "# Print model information\n",
    "print(f\"Model name: {model_name}\")\n",
    "print(f\"Number of layers: {model.config.n_layer}\")\n",
    "print(f\"Number of layers: {model.config.n_head}\")\n",
    "print(f\"Number of hidden units: {model.config.hidden_size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
