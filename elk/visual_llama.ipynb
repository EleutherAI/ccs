{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-1/spar/waree/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "from einops import rearrange, repeat\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:33<00:00, 11.19s/it]\n",
      "Some weights of the model checkpoint at huggyllama/llama-13b were not used when initializing LlamaModel: ['lm_head.weight']\n",
      "- This IS expected if you are initializing LlamaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LlamaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁This', '▁film', '▁is', '▁terrible', ',', '▁best', '▁to', '▁pass', '.']\n",
      "['<bos>', '▁This', '▁film', '▁is', '▁terrible', ',', '▁best', '▁to', '▁pass', '.']\n",
      "tensor([[    1,   910,  2706,   338, 16403, 29892,  1900,   304,  1209, 29889]])\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"huggyllama/llama-13b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize input sequence\n",
    "input_sequence = \"This film is terrible, best to pass.\"\n",
    "input_tokens = tokenizer.tokenize(input_sequence)\n",
    "print(input_tokens)\n",
    "input_tokens.insert(0, \"<bos>\")\n",
    "print(input_tokens)\n",
    "\n",
    "# Encode input sequence\n",
    "input_ids = tokenizer.encode(input_sequence, return_tensors=\"pt\")\n",
    "print(input_ids)\n",
    "\n",
    "# Generate hidden states\n",
    "outputs = model(input_ids, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "torch.Size([40, 10, 5120])\n"
     ]
    }
   ],
   "source": [
    "hidden_states = outputs.hidden_states\n",
    "print(len(hidden_states))\n",
    "cat_hidden_states = torch.cat(hidden_states[:-1], dim=0)\n",
    "print(cat_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_stack_layers(num_layers: int, prefix_path: str) -> torch.Tensor:\n",
    "    layers = []\n",
    "    for i in range(num_layers):\n",
    "        layer_path = f\"{prefix_path}/layer_{i}.pt\"\n",
    "        layer = torch.load(layer_path)\n",
    "        layers.append(layer.weight.cpu())\n",
    "    stacked = torch.cat(layers, dim=0)\n",
    "    return stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 5120])\n"
     ]
    }
   ],
   "source": [
    "path = '/home/waree/elk-reporters/huggyllama/llama-13b/sethapun/imdb_misspelled_0/llama13b-imdb0/reporters'\n",
    "rep_weights = load_and_stack_layers(model.config.num_hidden_layers,path)\n",
    "print(rep_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 10])\n"
     ]
    }
   ],
   "source": [
    "# Use einsum to do multiplication \n",
    "\n",
    "result = torch.einsum('bse,be->bs', cat_hidden_states, rep_weights)\n",
    "print(result.shape)\n",
    "\n",
    "sigmoid_result = torch.sigmoid(result)\n",
    "softmax_result = torch.softmax(result, dim = -1)\n",
    "torch.set_printoptions(precision=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.2e-03,  5.5e-03, -2.2e-02, -9.1e-03, -4.4e-02, -7.0e-03,  6.1e-02,\n",
      "         -7.1e-04, -9.6e-03,  4.9e-03],\n",
      "        [-1.2e+00, -5.9e-01, -1.8e-01, -6.5e-01, -3.5e-01, -9.4e-01, -2.4e-01,\n",
      "         -4.6e-01, -1.8e-01, -9.0e-01],\n",
      "        [-6.9e-01, -2.9e-01, -1.6e-01, -2.5e-01, -4.1e-01, -2.7e-01, -1.7e-01,\n",
      "         -7.4e-02,  5.3e-02, -2.7e-01],\n",
      "        [ 3.3e+01,  8.6e-02, -1.0e-01,  1.9e-02,  3.1e-01,  6.0e-03, -1.1e-01,\n",
      "         -1.5e-01, -2.3e-01, -1.5e-01],\n",
      "        [-3.5e+01, -8.6e-03,  7.5e-01,  2.8e-01, -4.6e-01, -1.6e-01,  2.4e-01,\n",
      "          2.7e-01,  2.4e-01,  1.0e-01],\n",
      "        [ 2.8e+01,  1.7e-01, -3.2e-01, -1.5e-01,  6.5e-01,  3.0e-01, -3.1e-01,\n",
      "         -6.8e-02, -2.5e-01, -1.6e-02],\n",
      "        [ 3.2e+01,  3.4e-01, -3.5e-01,  8.9e-02,  3.6e-01,  2.3e-01, -6.3e-01,\n",
      "         -4.9e-01, -3.1e-01, -1.8e-01],\n",
      "        [ 2.5e+01,  3.1e-01, -1.1e+00,  3.1e-02,  2.3e-01,  3.5e-01, -9.6e-01,\n",
      "         -5.5e-01, -4.7e-01,  2.8e-01],\n",
      "        [-2.7e+01,  4.0e-01,  1.0e+00,  3.1e-01,  2.2e-01,  4.7e-01,  1.6e+00,\n",
      "          6.0e-01,  2.2e-01, -5.2e-01],\n",
      "        [-7.7e+00, -1.0e+00, -6.7e-01, -8.3e-01, -9.4e-01, -8.0e-01,  9.2e-01,\n",
      "         -6.7e-03, -3.7e-01, -1.5e+00],\n",
      "        [-1.5e+00,  7.8e-01, -2.1e-01,  3.0e-01, -7.2e-01, -3.9e-01, -1.2e+00,\n",
      "         -4.1e-01, -2.0e-01,  1.3e+00],\n",
      "        [-1.5e+01,  8.0e-01, -1.8e-01,  3.6e-01, -5.4e-01, -1.4e-02, -1.1e+00,\n",
      "         -2.3e-01,  1.1e+00,  1.9e+00],\n",
      "        [-2.4e+01,  1.8e+00,  8.7e-01,  1.1e+00, -2.7e-01,  3.8e-02,  1.3e-01,\n",
      "          6.9e-01,  1.7e+00,  2.1e+00],\n",
      "        [-3.9e+01,  1.9e+00,  1.6e+00,  1.7e+00,  3.7e-01,  9.5e-01, -1.1e-01,\n",
      "          8.2e-01,  1.8e+00,  1.6e+00],\n",
      "        [-3.7e+01,  2.0e+00,  1.3e+00,  1.6e+00,  5.7e-01,  1.9e+00, -5.4e-01,\n",
      "          1.3e+00,  2.9e+00,  2.0e+00],\n",
      "        [-4.2e+01,  2.1e+00,  1.6e+00,  1.9e+00,  1.1e+00,  2.4e+00, -5.3e-01,\n",
      "          1.3e+00,  2.8e+00,  1.6e+00],\n",
      "        [-4.9e+01,  5.4e-01,  2.5e-01,  9.1e-01, -4.0e-01,  2.3e+00, -8.3e-01,\n",
      "          1.4e+00,  4.1e+00,  1.1e+00],\n",
      "        [-5.7e+01, -1.9e-02,  5.1e-02,  4.0e-01,  2.4e-01,  2.9e+00, -1.7e+00,\n",
      "          1.7e+00,  4.5e+00,  8.3e-01],\n",
      "        [-4.5e+01, -1.4e+00, -1.5e+00, -5.1e-01, -1.6e+00,  8.3e-01, -3.9e+00,\n",
      "          2.0e-01,  4.3e+00, -9.0e-01],\n",
      "        [-5.7e+01, -1.6e+00, -2.1e+00, -1.3e+00, -1.2e+00,  1.4e+00, -5.2e+00,\n",
      "         -8.1e-03,  6.0e+00, -4.2e-01],\n",
      "        [-3.9e+01, -2.1e+00, -2.4e+00, -2.2e+00, -2.1e+00,  9.2e-01, -5.7e+00,\n",
      "         -3.0e-03,  7.5e+00, -1.3e+00],\n",
      "        [-2.4e+01, -4.7e+00, -4.4e+00, -3.6e+00, -3.3e+00,  1.6e-01, -6.9e+00,\n",
      "         -1.8e+00,  8.5e+00, -3.5e+00],\n",
      "        [-2.3e+01, -5.5e+00, -5.3e+00, -4.5e+00, -3.6e+00,  3.0e-01, -8.1e+00,\n",
      "         -2.9e+00,  8.4e+00, -4.3e+00],\n",
      "        [-2.7e+01, -5.7e+00, -5.9e+00, -4.1e+00, -4.0e+00, -2.8e-02, -9.0e+00,\n",
      "         -3.8e+00,  8.4e+00, -4.6e+00],\n",
      "        [-4.0e+01, -3.3e+00, -3.9e+00, -2.0e+00, -1.8e+00,  2.5e+00, -9.2e+00,\n",
      "         -2.1e+00,  8.3e+00, -4.0e+00],\n",
      "        [-4.0e+01, -3.8e+00, -3.3e+00, -2.2e+00, -1.4e+00,  3.0e+00, -1.1e+01,\n",
      "         -5.1e+00,  6.9e+00, -4.5e+00],\n",
      "        [-3.1e+01, -3.3e+00, -3.0e+00, -3.0e+00, -6.2e-01,  3.6e+00, -1.2e+01,\n",
      "         -6.0e+00,  6.6e+00, -4.9e+00],\n",
      "        [-2.5e+01, -2.9e+00, -3.5e+00, -2.5e+00,  8.6e-01,  5.4e+00, -1.1e+01,\n",
      "         -6.4e+00,  6.0e+00, -4.2e+00],\n",
      "        [-3.2e+01, -2.8e+00, -2.6e+00, -2.4e+00,  1.1e+00,  6.0e+00, -1.1e+01,\n",
      "         -6.2e+00,  6.3e+00, -2.9e+00],\n",
      "        [-3.2e+01, -2.9e+00, -3.3e+00, -3.2e+00,  5.5e-01,  4.8e+00, -1.3e+01,\n",
      "         -8.2e+00,  5.9e+00, -3.7e+00],\n",
      "        [-3.8e+01, -2.9e+00, -3.8e+00, -4.1e+00, -8.0e-01,  3.6e+00, -1.4e+01,\n",
      "         -9.1e+00,  6.0e+00, -4.9e+00],\n",
      "        [-3.8e+01, -1.6e+00, -2.6e+00, -4.1e+00, -7.4e-01,  2.5e+00, -1.5e+01,\n",
      "         -9.0e+00,  6.4e+00, -5.5e+00],\n",
      "        [-2.8e+01, -1.8e+00, -3.3e+00, -4.4e+00, -1.2e+00,  2.6e+00, -1.5e+01,\n",
      "         -8.6e+00,  6.2e+00, -6.3e+00],\n",
      "        [-2.3e+01, -2.5e+00, -2.9e+00, -4.7e+00, -3.1e-01,  3.3e+00, -1.4e+01,\n",
      "         -7.4e+00,  7.1e+00, -5.5e+00],\n",
      "        [-3.1e+01, -2.8e+00, -2.8e+00, -3.6e+00, -5.7e-01,  3.0e+00, -1.2e+01,\n",
      "         -6.7e+00,  6.4e+00, -6.1e+00],\n",
      "        [-3.3e+01, -3.5e+00, -2.9e+00, -5.0e+00, -1.1e+00,  2.1e+00, -1.3e+01,\n",
      "         -7.2e+00,  6.9e+00, -7.1e+00],\n",
      "        [-1.6e+01, -4.5e+00, -3.1e+00, -5.9e+00, -1.7e+00,  1.6e+00, -1.4e+01,\n",
      "         -9.0e+00,  6.8e+00, -7.3e+00],\n",
      "        [-6.2e+01, -4.3e+00, -3.0e+00, -5.2e+00, -4.4e-01,  1.2e+00, -1.5e+01,\n",
      "         -9.3e+00,  7.5e+00, -8.0e+00],\n",
      "        [-2.6e+01, -2.6e+00, -1.8e+00, -4.9e+00, -5.0e-02, -1.4e-01, -1.6e+01,\n",
      "         -1.3e+01,  5.8e+00, -8.6e+00],\n",
      "        [-4.8e-01,  9.5e+00,  3.7e+00,  4.2e+00,  6.7e+00,  7.3e+00, -1.4e+01,\n",
      "         -5.3e+00,  1.3e+01, -1.1e+00]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sigmoid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(softmax_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m# Create plotly figure\u001b[39;00m\n\u001b[1;32m     21\u001b[0m fig \u001b[39m=\u001b[39m go\u001b[39m.\u001b[39mFigure(data\u001b[39m=\u001b[39m[heatmap], layout\u001b[39m=\u001b[39mlayout)\n\u001b[0;32m---> 23\u001b[0m fig\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[0;32m/mnt/ssd-1/spar/waree/miniconda3/lib/python3.10/site-packages/plotly/basedatatypes.py:3390\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3357\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3358\u001b[0m \u001b[39mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[1;32m   3359\u001b[0m \u001b[39mspecified by the renderer argument\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3386\u001b[0m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3387\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3388\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n\u001b[0;32m-> 3390\u001b[0m \u001b[39mreturn\u001b[39;00m pio\u001b[39m.\u001b[39;49mshow(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/ssd-1/spar/waree/miniconda3/lib/python3.10/site-packages/plotly/io/_renderers.py:396\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    392\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m         )\n\u001b[1;32m    395\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nbformat \u001b[39mor\u001b[39;00m LooseVersion(nbformat\u001b[39m.\u001b[39m__version__) \u001b[39m<\u001b[39m LooseVersion(\u001b[39m\"\u001b[39m\u001b[39m4.2.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 396\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    397\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m         )\n\u001b[1;32m    400\u001b[0m     ipython_display\u001b[39m.\u001b[39mdisplay(bundle, raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    402\u001b[0m \u001b[39m# external renderers\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "import torch\n",
    "\n",
    "# Create color scale for heatmap\n",
    "color_scale = [[0, '#FFFFFF'], [1, '#FF0000']] # white to red\n",
    "\n",
    "# Convert tensor to numpy array and detach gradients\n",
    "credences_np = result.detach().numpy()\n",
    "\n",
    "# Create plotly heatmap\n",
    "heatmap = go.Heatmap(z=credences_np, colorscale=color_scale)\n",
    "\n",
    "# Create plot layout\n",
    "layout = go.Layout(title='Credences for Input Tokens',\n",
    "                   xaxis=dict(tickvals=list(range(len(input_tokens))),\n",
    "                              ticktext=input_tokens,\n",
    "                              tickangle=45))\n",
    "\n",
    "# Create plotly figure\n",
    "fig = go.Figure(data=[heatmap], layout=layout)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 10])\n"
     ]
    }
   ],
   "source": [
    "# Use einsum to do multiplication \n",
    "\n",
    "rep_weights_repeat = repeat(rep_weights, 'b e -> b c e', c=len(input_tokens) + 1)\n",
    "result = torch.einsum('bse,bse->bs', cat_hidden_states, rep_weights_repeat)\n",
    "print(result.shape)\n",
    "\n",
    "sigmoid_result = torch.sigmoid(result)\n",
    "softmax_result = torch.softmax(result, dim = -1)\n",
    "torch.set_printoptions(precision=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.2e-03,  5.5e-03, -2.2e-02, -9.1e-03, -4.4e-02, -7.0e-03,  6.1e-02,\n",
      "         -7.1e-04, -9.6e-03,  4.9e-03],\n",
      "        [-1.2e+00, -5.9e-01, -1.8e-01, -6.5e-01, -3.5e-01, -9.4e-01, -2.4e-01,\n",
      "         -4.6e-01, -1.8e-01, -9.0e-01],\n",
      "        [-6.9e-01, -2.9e-01, -1.6e-01, -2.5e-01, -4.1e-01, -2.7e-01, -1.7e-01,\n",
      "         -7.4e-02,  5.3e-02, -2.7e-01],\n",
      "        [ 3.3e+01,  8.6e-02, -1.0e-01,  1.9e-02,  3.1e-01,  6.0e-03, -1.1e-01,\n",
      "         -1.5e-01, -2.3e-01, -1.5e-01],\n",
      "        [-3.5e+01, -8.6e-03,  7.5e-01,  2.8e-01, -4.6e-01, -1.6e-01,  2.4e-01,\n",
      "          2.7e-01,  2.4e-01,  1.0e-01],\n",
      "        [ 2.8e+01,  1.7e-01, -3.2e-01, -1.5e-01,  6.5e-01,  3.0e-01, -3.1e-01,\n",
      "         -6.8e-02, -2.5e-01, -1.6e-02],\n",
      "        [ 3.2e+01,  3.4e-01, -3.5e-01,  8.9e-02,  3.6e-01,  2.3e-01, -6.3e-01,\n",
      "         -4.9e-01, -3.1e-01, -1.8e-01],\n",
      "        [ 2.5e+01,  3.1e-01, -1.1e+00,  3.1e-02,  2.3e-01,  3.5e-01, -9.6e-01,\n",
      "         -5.5e-01, -4.7e-01,  2.8e-01],\n",
      "        [-2.7e+01,  4.0e-01,  1.0e+00,  3.1e-01,  2.2e-01,  4.7e-01,  1.6e+00,\n",
      "          6.0e-01,  2.2e-01, -5.2e-01],\n",
      "        [-7.7e+00, -1.0e+00, -6.7e-01, -8.3e-01, -9.4e-01, -8.0e-01,  9.2e-01,\n",
      "         -6.7e-03, -3.7e-01, -1.5e+00],\n",
      "        [-1.5e+00,  7.8e-01, -2.1e-01,  3.0e-01, -7.2e-01, -3.9e-01, -1.2e+00,\n",
      "         -4.1e-01, -2.0e-01,  1.3e+00],\n",
      "        [-1.5e+01,  8.0e-01, -1.8e-01,  3.6e-01, -5.4e-01, -1.4e-02, -1.1e+00,\n",
      "         -2.3e-01,  1.1e+00,  1.9e+00],\n",
      "        [-2.4e+01,  1.8e+00,  8.7e-01,  1.1e+00, -2.7e-01,  3.8e-02,  1.3e-01,\n",
      "          6.9e-01,  1.7e+00,  2.1e+00],\n",
      "        [-3.9e+01,  1.9e+00,  1.6e+00,  1.7e+00,  3.7e-01,  9.5e-01, -1.1e-01,\n",
      "          8.2e-01,  1.8e+00,  1.6e+00],\n",
      "        [-3.7e+01,  2.0e+00,  1.3e+00,  1.6e+00,  5.7e-01,  1.9e+00, -5.4e-01,\n",
      "          1.3e+00,  2.9e+00,  2.0e+00],\n",
      "        [-4.2e+01,  2.1e+00,  1.6e+00,  1.9e+00,  1.1e+00,  2.4e+00, -5.3e-01,\n",
      "          1.3e+00,  2.8e+00,  1.6e+00],\n",
      "        [-4.9e+01,  5.4e-01,  2.5e-01,  9.1e-01, -4.0e-01,  2.3e+00, -8.3e-01,\n",
      "          1.4e+00,  4.1e+00,  1.1e+00],\n",
      "        [-5.7e+01, -1.9e-02,  5.1e-02,  4.0e-01,  2.4e-01,  2.9e+00, -1.7e+00,\n",
      "          1.7e+00,  4.5e+00,  8.3e-01],\n",
      "        [-4.5e+01, -1.4e+00, -1.5e+00, -5.1e-01, -1.6e+00,  8.3e-01, -3.9e+00,\n",
      "          2.0e-01,  4.3e+00, -9.0e-01],\n",
      "        [-5.7e+01, -1.6e+00, -2.1e+00, -1.3e+00, -1.2e+00,  1.4e+00, -5.2e+00,\n",
      "         -8.1e-03,  6.0e+00, -4.2e-01],\n",
      "        [-3.9e+01, -2.1e+00, -2.4e+00, -2.2e+00, -2.1e+00,  9.2e-01, -5.7e+00,\n",
      "         -3.0e-03,  7.5e+00, -1.3e+00],\n",
      "        [-2.4e+01, -4.7e+00, -4.4e+00, -3.6e+00, -3.3e+00,  1.6e-01, -6.9e+00,\n",
      "         -1.8e+00,  8.5e+00, -3.5e+00],\n",
      "        [-2.3e+01, -5.5e+00, -5.3e+00, -4.5e+00, -3.6e+00,  3.0e-01, -8.1e+00,\n",
      "         -2.9e+00,  8.4e+00, -4.3e+00],\n",
      "        [-2.7e+01, -5.7e+00, -5.9e+00, -4.1e+00, -4.0e+00, -2.8e-02, -9.0e+00,\n",
      "         -3.8e+00,  8.4e+00, -4.6e+00],\n",
      "        [-4.0e+01, -3.3e+00, -3.9e+00, -2.0e+00, -1.8e+00,  2.5e+00, -9.2e+00,\n",
      "         -2.1e+00,  8.3e+00, -4.0e+00],\n",
      "        [-4.0e+01, -3.8e+00, -3.3e+00, -2.2e+00, -1.4e+00,  3.0e+00, -1.1e+01,\n",
      "         -5.1e+00,  6.9e+00, -4.5e+00],\n",
      "        [-3.1e+01, -3.3e+00, -3.0e+00, -3.0e+00, -6.2e-01,  3.6e+00, -1.2e+01,\n",
      "         -6.0e+00,  6.6e+00, -4.9e+00],\n",
      "        [-2.5e+01, -2.9e+00, -3.5e+00, -2.5e+00,  8.6e-01,  5.4e+00, -1.1e+01,\n",
      "         -6.4e+00,  6.0e+00, -4.2e+00],\n",
      "        [-3.2e+01, -2.8e+00, -2.6e+00, -2.4e+00,  1.1e+00,  6.0e+00, -1.1e+01,\n",
      "         -6.2e+00,  6.3e+00, -2.9e+00],\n",
      "        [-3.2e+01, -2.9e+00, -3.3e+00, -3.2e+00,  5.5e-01,  4.8e+00, -1.3e+01,\n",
      "         -8.2e+00,  5.9e+00, -3.7e+00],\n",
      "        [-3.8e+01, -2.9e+00, -3.8e+00, -4.1e+00, -8.0e-01,  3.6e+00, -1.4e+01,\n",
      "         -9.1e+00,  6.0e+00, -4.9e+00],\n",
      "        [-3.8e+01, -1.6e+00, -2.6e+00, -4.1e+00, -7.4e-01,  2.5e+00, -1.5e+01,\n",
      "         -9.0e+00,  6.4e+00, -5.5e+00],\n",
      "        [-2.8e+01, -1.8e+00, -3.3e+00, -4.4e+00, -1.2e+00,  2.6e+00, -1.5e+01,\n",
      "         -8.6e+00,  6.2e+00, -6.3e+00],\n",
      "        [-2.3e+01, -2.5e+00, -2.9e+00, -4.7e+00, -3.1e-01,  3.3e+00, -1.4e+01,\n",
      "         -7.4e+00,  7.1e+00, -5.5e+00],\n",
      "        [-3.1e+01, -2.8e+00, -2.8e+00, -3.6e+00, -5.7e-01,  3.0e+00, -1.2e+01,\n",
      "         -6.7e+00,  6.4e+00, -6.1e+00],\n",
      "        [-3.3e+01, -3.5e+00, -2.9e+00, -5.0e+00, -1.1e+00,  2.1e+00, -1.3e+01,\n",
      "         -7.2e+00,  6.9e+00, -7.1e+00],\n",
      "        [-1.6e+01, -4.5e+00, -3.1e+00, -5.9e+00, -1.7e+00,  1.6e+00, -1.4e+01,\n",
      "         -9.0e+00,  6.8e+00, -7.3e+00],\n",
      "        [-6.2e+01, -4.3e+00, -3.0e+00, -5.2e+00, -4.4e-01,  1.2e+00, -1.5e+01,\n",
      "         -9.3e+00,  7.5e+00, -8.0e+00],\n",
      "        [-2.6e+01, -2.6e+00, -1.8e+00, -4.9e+00, -5.0e-02, -1.4e-01, -1.6e+01,\n",
      "         -1.3e+01,  5.8e+00, -8.6e+00],\n",
      "        [-4.8e-01,  9.5e+00,  3.7e+00,  4.2e+00,  6.7e+00,  7.3e+00, -1.4e+01,\n",
      "         -5.3e+00,  1.3e+01, -1.1e+00]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
