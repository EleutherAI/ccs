{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/miniconda3/envs/rwkv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rwkv_hf import RWKVModel, RWKVTokenizer\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "os.environ[\"RWKV_CUDA_ON\"] = \"0\"\n",
    "os.environ[\"RWKV_JIT_ON\"] = '1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RWKV_JIT_ON 1 RWKV_CUDA_ON 0 RESCALE_LAYER 6\n",
      "\n",
      "Loading /home/kyle/.cache/huggingface/hub/models--BlinkDL--rwkv-4-pile-7b/snapshots/ed39f1079ee4f57da0b0471f3ed1bd0fd1f45e52/RWKV-4-Pile-7B-20221115-8047.pth ...\n",
      "Strategy: (total 32+1=33 layers)\n",
      "* cuda [float16, float16], store 33 layers\n",
      "0-cuda-float16-float16 1-cuda-float16-float16 2-cuda-float16-float16 3-cuda-float16-float16 4-cuda-float16-float16 5-cuda-float16-float16 6-cuda-float16-float16 7-cuda-float16-float16 8-cuda-float16-float16 9-cuda-float16-float16 10-cuda-float16-float16 11-cuda-float16-float16 12-cuda-float16-float16 13-cuda-float16-float16 14-cuda-float16-float16 15-cuda-float16-float16 16-cuda-float16-float16 17-cuda-float16-float16 18-cuda-float16-float16 19-cuda-float16-float16 20-cuda-float16-float16 21-cuda-float16-float16 22-cuda-float16-float16 23-cuda-float16-float16 24-cuda-float16-float16 25-cuda-float16-float16 26-cuda-float16-float16 27-cuda-float16-float16 28-cuda-float16-float16 29-cuda-float16-float16 30-cuda-float16-float16 31-cuda-float16-float16 32-cuda-float16-float16 \n",
      "emb.weight                        f16      cpu  50277  4096 \n",
      "blocks.0.ln1.weight               f16   cuda:0   4096       \n",
      "blocks.0.ln1.bias                 f16   cuda:0   4096       \n",
      "blocks.0.ln2.weight               f16   cuda:0   4096       \n",
      "blocks.0.ln2.bias                 f16   cuda:0   4096       \n",
      "blocks.0.att.time_decay           f32   cuda:0   4096       \n",
      "blocks.0.att.time_first           f32   cuda:0   4096       \n",
      "blocks.0.att.time_mix_k           f16   cuda:0   4096       \n",
      "blocks.0.att.time_mix_v           f16   cuda:0   4096       \n",
      "blocks.0.att.time_mix_r           f16   cuda:0   4096       \n",
      "blocks.0.att.key.weight           f16   cuda:0   4096  4096 \n",
      "blocks.0.att.value.weight         f16   cuda:0   4096  4096 \n",
      "blocks.0.att.receptance.weight    f16   cuda:0   4096  4096 \n",
      "blocks.0.att.output.weight        f16   cuda:0   4096  4096 \n",
      "blocks.0.ffn.time_mix_k           f16   cuda:0   4096       \n",
      "blocks.0.ffn.time_mix_r           f16   cuda:0   4096       \n",
      "blocks.0.ffn.key.weight           f16   cuda:0   4096 16384 \n",
      "blocks.0.ffn.receptance.weight    f16   cuda:0   4096  4096 \n",
      "blocks.0.ffn.value.weight         f16   cuda:0  16384  4096 \n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "blocks.31.ln1.weight              f16   cuda:0   4096       \n",
      "blocks.31.ln1.bias                f16   cuda:0   4096       \n",
      "blocks.31.ln2.weight              f16   cuda:0   4096       \n",
      "blocks.31.ln2.bias                f16   cuda:0   4096       \n",
      "blocks.31.att.time_decay          f32   cuda:0   4096       \n",
      "blocks.31.att.time_first          f32   cuda:0   4096       \n",
      "blocks.31.att.time_mix_k          f16   cuda:0   4096       \n",
      "blocks.31.att.time_mix_v          f16   cuda:0   4096       \n",
      "blocks.31.att.time_mix_r          f16   cuda:0   4096       \n",
      "blocks.31.att.key.weight          f16   cuda:0   4096  4096 \n",
      "blocks.31.att.value.weight        f16   cuda:0   4096  4096 \n",
      "blocks.31.att.receptance.weight   f16   cuda:0   4096  4096 \n",
      "blocks.31.att.output.weight       f16   cuda:0   4096  4096 \n",
      "blocks.31.ffn.time_mix_k          f16   cuda:0   4096       \n",
      "blocks.31.ffn.time_mix_r          f16   cuda:0   4096       \n",
      "blocks.31.ffn.key.weight          f16   cuda:0   4096 16384 \n",
      "blocks.31.ffn.receptance.weight   f16   cuda:0   4096  4096 \n",
      "blocks.31.ffn.value.weight        f16   cuda:0  16384  4096 \n",
      "ln_out.weight                     f16   cuda:0   4096       \n",
      "ln_out.bias                       f16   cuda:0   4096       \n",
      "head.weight                       f16   cuda:0   4096 50277 \n"
     ]
    }
   ],
   "source": [
    "model = RWKVModel(\"cuda\")\n",
    "tokenizer = RWKVTokenizer(\"/home/kyle/repos/elk/elk/rwkv_lm/20B_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned logits in shape torch.Size([50277])\n",
      "Returned 160 hidden states in shape torch.Size([4096])\n",
      "The next token is \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"The following movie review expresses what sentiment? George P. Cosmatos\\' \\\"Rambo: First Blood Part II\\\" is pure wish-fulfillment. The United States clearly didn\\'t win the war in Vietnam. They caused damage to this country beyond the imaginable and this movie continues the fairy story of the oh-so innocent soldiers. The only bad guys were the leaders of the nation, who made this war happen. The character of Rambo is perfect to notice this. He is extremely patriotic, bemoans that US-Americans didn\\'t appreciate and celebrate the achievements of the single soldier, but has nothing but distrust for leading officers and politicians. Like every film that defends the war (e.g. \\\"We Were Soldiers\\\") also this one avoids the need to give a comprehensible reason for the engagement in South Asia. And for that matter also the reason for every single US-American soldier that was there. Instead, Rambo gets to take revenge for the wounds of a whole nation. It would have been better to work on how to deal with the memories, rather than suppressing them. \\\"Do we get to win this time?\\\" Yes, you do.\\n\\nnegative\"\n",
    "tokens = tokenizer(text, return_tensors=\"pt\")\n",
    "response = model(**tokens)\n",
    "print(f\"Returned logits in shape {response.logits.shape}\")\n",
    "print(f\"Returned {len(response.hidden_states)} hidden states in shape {response.hidden_states[0].shape}\")\n",
    "print(f\"The next token is {tokenizer.decode([response.logits.argmax(-1).item()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(torch.float32, 96), (torch.float16, 64)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The hidden states have mixed type?\n",
    "hidden_states = response.hidden_states\n",
    "types = [state.dtype for state in hidden_states]\n",
    "unique_types = set(types)\n",
    "[(t, types.count(t)) for t in unique_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16,\n",
       " torch.float16,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float32,\n",
       " torch.float16]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
