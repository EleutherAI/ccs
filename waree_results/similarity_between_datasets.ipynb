{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-2/spar/waree/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "from einops import rearrange, repeat\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_layers = 40\n",
    "layers_arr = np.arange(num_hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_stack_layers(num_layers: int, reporter_type: 'str', prefix_path: str) -> torch.Tensor:\n",
    "    layers = []\n",
    "    if reporter_type == 'lr' or reporter_type == 'lr2':\n",
    "        for i in range(num_layers):\n",
    "            layer_path = f\"{prefix_path}/layer_{i}.pt\"\n",
    "            layer = torch.load(layer_path)\n",
    "            layers.append(layer.linear.weight.detach().cpu())\n",
    "        stacked = torch.cat(layers, dim=0)\n",
    "        return stacked\n",
    "    elif reporter_type == 'vinc':\n",
    "        for i in range(num_layers):\n",
    "            layer_path = f\"{prefix_path}/layer_{i}.pt\"\n",
    "            layer = torch.load(layer_path)\n",
    "            layers.append(layer.weight.detach().cpu())\n",
    "        stacked = torch.cat(layers, dim=0)\n",
    "        return stacked\n",
    "    elif reporter_type == 'ccs':\n",
    "        for i in range(num_layers):\n",
    "            layer_path = f\"{prefix_path}/layer_{i}.pt\"\n",
    "            layer = torch.load(layer_path)\n",
    "            layers.append(layer.probe[0].weight.detach().cpu())\n",
    "        stacked = torch.cat(layers, dim=0)\n",
    "        return stacked\n",
    "\n",
    "def get_norm_weights(data: dict, dataset: str, ccs_path: str, vinc_path: str, lr_path: str, lr2_path: str):\n",
    "    \n",
    "    #for reporter,path in zip(['ccs','vinc', 'lr', 'lr2'], [ccs_path,vinc_path,lr_path,lr2_path]):\n",
    "    for reporter,path in zip(['ccs','vinc'], [ccs_path,vinc_path]):\n",
    "        weights = load_and_stack_layers(num_hidden_layers, reporter, path)\n",
    "        magnitude = torch.norm(weights, dim=-1, keepdim=True)\n",
    "        data[(dataset, reporter)] = weights/magnitude\n",
    "    \n",
    "\n",
    "def similarity(rep1_normalized, rep2_normalized):\n",
    "    cosine_sim = torch.einsum(\"ij,ij->i\", rep1_normalized, rep2_normalized)\n",
    "    return cosine_sim\n",
    "\n",
    "\n",
    "def similarity_single_layer(rep1_normalized, rep1_layer: int, rep2_normalized):\n",
    "    cosine_sim = torch.einsum(\"j,ij->i\", rep1_normalized[rep1_layer], rep2_normalized)\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m lr2_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/home/waree/elk-reporters/test-huggyllama/llama-13b/sethapun/arithmetic_2as_1to\u001b[39m\u001b[39m{\u001b[39;00md\u001b[39m}\u001b[39;00m\u001b[39m/vinc/lr_models\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     10\u001b[0m vinc_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/home/waree/elk-reporters/test-huggyllama/llama-13b/sethapun/arithmetic_2as_1to\u001b[39m\u001b[39m{\u001b[39;00md\u001b[39m}\u001b[39;00m\u001b[39m/vinc/reporters\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m get_norm_weights(data, dataset, ccs_path, vinc_path, lr_path, lr2_path)\n",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m, in \u001b[0;36mget_norm_weights\u001b[0;34m(data, dataset, ccs_path, vinc_path, lr_path, lr2_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_norm_weights\u001b[39m(data: \u001b[39mdict\u001b[39m, dataset: \u001b[39mstr\u001b[39m, ccs_path: \u001b[39mstr\u001b[39m, vinc_path: \u001b[39mstr\u001b[39m, lr_path: \u001b[39mstr\u001b[39m, lr2_path: \u001b[39mstr\u001b[39m):\n\u001b[1;32m     26\u001b[0m     \n\u001b[1;32m     27\u001b[0m     \u001b[39m#for reporter,path in zip(['ccs','vinc', 'lr', 'lr2'], [ccs_path,vinc_path,lr_path,lr2_path]):\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[39mfor\u001b[39;00m reporter,path \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m([\u001b[39m'\u001b[39m\u001b[39mccs\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mvinc\u001b[39m\u001b[39m'\u001b[39m], [ccs_path,vinc_path]):\n\u001b[0;32m---> 29\u001b[0m         weights \u001b[39m=\u001b[39m load_and_stack_layers(num_hidden_layers, reporter, path)\n\u001b[1;32m     30\u001b[0m         magnitude \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnorm(weights, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m         data[(dataset, reporter)] \u001b[39m=\u001b[39m weights\u001b[39m/\u001b[39mmagnitude\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mload_and_stack_layers\u001b[0;34m(num_layers, reporter_type, prefix_path)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_layers):\n\u001b[1;32m     19\u001b[0m     layer_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mprefix_path\u001b[39m}\u001b[39;00m\u001b[39m/layer_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m     layer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(layer_path)\n\u001b[1;32m     21\u001b[0m     layers\u001b[39m.\u001b[39mappend(layer\u001b[39m.\u001b[39mprobe[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu())\n\u001b[1;32m     22\u001b[0m stacked \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(layers, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/waree/miniconda3/lib/python3.10/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    810\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/waree/miniconda3/lib/python3.10/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1174\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/waree/miniconda3/lib/python3.10/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1144\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/waree/miniconda3/lib/python3.10/site-packages/torch/serialization.py:1116\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1112\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39mUntypedStorage)\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1116\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1117\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m     _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1120\u001b[0m \u001b[39mif\u001b[39;00m typed_storage\u001b[39m.\u001b[39m_data_ptr() \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1121\u001b[0m     loaded_storages[key] \u001b[39m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/waree/miniconda3/lib/python3.10/site-packages/torch/serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 217\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    218\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/waree/miniconda3/lib/python3.10/site-packages/torch/serialization.py:187\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mUntypedStorage(obj\u001b[39m.\u001b[39mnbytes(), device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(location))\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39;49mcuda(device)\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/waree/miniconda3/lib/python3.10/site-packages/torch/_utils.py:81\u001b[0m, in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[39mreturn\u001b[39;00m new_type(indices, values, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m     80\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     untyped_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mUntypedStorage(\n\u001b[1;32m     82\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize(), device\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     83\u001b[0m     )\n\u001b[1;32m     84\u001b[0m     untyped_storage\u001b[39m.\u001b[39mcopy_(\u001b[39mself\u001b[39m, non_blocking)\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for d in [1,5,10]:\n",
    "\n",
    "    dataset = f\"arith{d}\"\n",
    "\n",
    "    lr_path = f'/home/waree/elk-reporters/test-huggyllama/llama-13b/sethapun/arithmetic_2as_1to{d}/ccs/lr_models'\n",
    "    ccs_path = f'/home/waree/elk-reporters/test-huggyllama/llama-13b/sethapun/arithmetic_2as_1to{d}/ccs/reporters'\n",
    "    lr2_path = f'/home/waree/elk-reporters/test-huggyllama/llama-13b/sethapun/arithmetic_2as_1to{d}/vinc/lr_models'\n",
    "    vinc_path = f'/home/waree/elk-reporters/test-huggyllama/llama-13b/sethapun/arithmetic_2as_1to{d}/vinc/reporters'\n",
    "\n",
    "    get_norm_weights(data, dataset, ccs_path, vinc_path, lr_path, lr2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {}\n",
    "\n",
    "for d in [0,5,10,30,50]:\n",
    "\n",
    "    dataset = f\"imdb_misspelled_{d}\"\n",
    "\n",
    "    lr_path = f'/home/waree/elk-reporters/arith-huggyllama/llama-13b/sethapun/imdb_misspelled_{d}/ccs/lr_models'\n",
    "    ccs_path = f'/home/waree/elk-reporters/arith-huggyllama/llama-13b/sethapun/imdb_misspelled_{d}/ccs/reporters'\n",
    "    lr2_path = f'/home/waree/elk-reporters/arith-huggyllama/llama-13b/sethapun/imdb_misspelled_{d}/vinc/lr_models'\n",
    "    vinc_path = f'/home/waree/elk-reporters/arith-huggyllama/llama-13b/sethapun/imdb_misspelled_{d}/vinc/reporters'\n",
    "\n",
    "    get_norm_weights(data2, dataset, ccs_path, vinc_path, lr_path, lr2_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
